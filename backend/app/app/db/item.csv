title,abstract,keywords,authors,url,from_source
Learning Similarity Metrics for Volumetric Simulations with Multiscale CNNs,"Simulations that produce three-dimensional data are ubiquitous in science, ranging from fluid flows to plasma physics. We propose a similarity model based on entropy, which allows for the creation of physically meaningful ground truth distances for the similarity assessment of scalar and vectorial data, produced from transport and motion-based simulations. Utilizing two data acquisition methods derived from this model, we create collections of fields from numerical PDE solvers and existing simulation data repositories. Furthermore, a multiscale CNN architecture that computes a volumetric similarity metric (VolSiM) is proposed. To the best of our knowledge this is the first learning method inherently designed to address the challenges arising for the similarity assessment of high-dimensional simulation data. Additionally, the tradeoff between a large batch size and an accurate correlation computation for correlation-based loss functions is investigated, and the metric's invariance with respect to rotation and scale operations is analyzed. Finally, the robustness and generalization of VolSiM is evaluated on a large range of test data, as well as a particularly challenging turbulence case study, that is close to potential real-world applications.","[""ML: Learning Preferences or Rankings"", ""APP: Natural Sciences"", ""ML: Representation Learning"", ""ML: Applications""]","[""Georg Kohl"", ""Li-Wei Chen"", ""Nils Thuerey""]",https://ojs.aaai.org/index.php/AAAI/article/view/26007/25779,AAAI
Large-State Reinforcement Learning for Hyper-Heuristics,"Hyper-heuristics are a domain-independent problem solving approach where the main task is to select effective chains of problem-specific low-level heuristics on the fly for an unseen instance. This task can be seen as a reinforcement learning problem, however, the information available to the hyper-heuristic is very limited, usually leading to very limited state representations. In this work, for the first time we use the trajectory of solution changes for a larger set of features for reinforcement learning in the novel hyper-heuristic LAST-RL (Large-State Reinforcement Learning). Further, we introduce a probability distribution for the exploration case in our epsilon-greedy policy that is based on the idea of Iterated Local Search to increase the chance to sample good chains of low-level heuristics. The benefit of the collaboration of our novel components is shown on the academic benchmark of the Cross Domain Heuristic Challenge 2011 consisting of six different problem domains. Our approach can provide state-of-the-art results on this benchmark where it outperforms recent hyper-heuristics based on reinforcement learning, and also demonstrates high performance on a benchmark of complex real-life personnel scheduling domains.","[""SO: Metareasoning and Metaheuristics"", ""ML: Reinforcement Learning Algorithms"", ""PRS: Applications"", ""SO: Heuristic Search""]","[""Lucas Kletzander"", ""Nysret Musliu""]",https://ojs.aaai.org/index.php/AAAI/article/view/26466/26238,AAAI
Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation,"Continual Test-Time Adaptation (CTTA) aims to adapt the source model to continually changing unlabeled target domains without access to the source data. Existing methods mainly focus on model-based adaptation in a self-training manner, such as predicting pseudo labels for new domain datasets. Since pseudo labels are noisy and unreliable, these methods suffer from catastrophic forgetting and error accumulation when dealing with dynamic data distributions. Motivated by the prompt learning in NLP, in this paper, we propose to learn an image-layer visual domain prompt for target domains while having the source model parameters frozen. During testing, the changing target datasets can be adapted to the source model by reformulating the input data with the learned visual prompts. Specifically, we devise two types of prompts, i.e., domains-specific prompts and domains-agnostic prompts, to extract current domain knowledge and maintain the domain-shared knowledge in the continual adaptation. Furthermore, we design a homeostasis-based adaptation strategy to suppress domain-sensitive parameters in domain-invariant prompts to learn domain-shared knowledge more effectively. This transition from the model-dependent paradigm to the model-free one enables us to bypass the catastrophic forgetting and error accumulation problems. Experiments show that our proposed method achieves significant performance gains over state-of-the-art methods on four widely-used benchmarks, including CIFAR-10C, CIFAR-100C, ImageNet-C, and VLCS datasets.","[""ML: Transfer"", ""Domain Adaptation"", ""Multi-Task Learning"", ""CV: Low Level & Physics-Based Vision"", ""ML: Lifelong and Continual Learning"", ""ML: Unsupervised & Self-Supervised Learning""]","[""Yulu Gan"", ""Yan Bai"", ""Yihang Lou"", ""Xianzheng Ma"", ""Renrui Zhang"", ""Nian Shi"", ""Lin Luo""]",https://ojs.aaai.org/index.php/AAAI/article/view/25922/25694,AAAI
MIGA: A Unified Multi-Task Generation Framework for Conversational Text-to-SQL,"Conversational text-to-SQL is designed to translate multi-turn natural language questions into their corresponding SQL queries. Most advanced conversational text-to-SQL methods are incompatible with generative pre-trained language models (PLMs), such as T5. In this paper, we present a two-stage unified MultI-task Generation frAmework (MIGA) that leverages PLMsâ€?ability to tackle conversational text-to-SQL. In the pre-training stage, MIGA first decomposes the main task into several related sub-tasks and then unifies them into the same sequence-to-sequence (Seq2Seq) paradigm with task-specific natural language prompts to boost the main task from multi-task training. Later in the fine-tuning stage, we propose four SQL perturbations to alleviate the error propagation problem. MIGA tends to achieve state-of-the-art performance on two benchmarks (SparC and CoSQL). We also provide extensive analyses and discussions to shed light on some new perspectives for conversational text-to-SQL.","[""SNLP: Generation"", ""ML: Transfer"", ""Domain Adaptation"", ""Multi-Task Learning"", ""SNLP: Conversational AI/Dialogue Systems"", ""SNLP: Language Models""]","[""Yingwen Fu"", ""Wenjie Ou"", ""Zhou Yu"", ""Yue Lin""]",https://ojs.aaai.org/index.php/AAAI/article/view/26504/26276,AAAI
Heterogeneous Graph Learning for Multi-Modal Medical Data Analysis,"Routine clinical visits of a patient produce not only image data, but also non-image data containing clinical information regarding the patient, i.e., medical data is multi-modal in nature. Such heterogeneous modalities offer different and complementary perspectives on the same patient, resulting in more accurate clinical decisions when they are properly combined. However, despite its significance, how to effectively fuse the multi-modal medical data into a unified framework has received relatively little attention. In this paper, we propose an effective graph-based framework called HetMed (Heterogeneous Graph Learning for Multi-modal Medical Data Analysis) for fusing the multi-modal medical data.
Specifically, we construct a multiplex network that incorporates multiple types of non-image features of patients to capture the complex relationship between patients in a systematic way, which leads to more accurate clinical decisions. Extensive experiments on various real-world datasets demonstrate the superiority and practicality of HetMed. The source code for HetMed is available at https://github.com/Sein-Kim/Multimodal-Medical.","[""APP: Healthcare"", ""Medicine & Wellness"", ""CV: Medical and Biological Imaging""]","[""Sein Kim"", ""Namkyeong Lee"", ""Junseok Lee"", ""Dongmin Hyun"", ""Chanyoung Park""]",https://ojs.aaai.org/index.php/AAAI/article/view/25643/25415,AAAI
FASTDIAGP: An Algorithm for Parallelized Direct Diagnosis,"Constraint-based applications attempt to identify a solution that meets all defined user requirements. If the requirements are inconsistent with the underlying constraint set, algorithms that compute diagnoses for inconsistent constraints should be implemented to help users resolve the â€œno solution could be foundâ€?dilemma. FastDiag is a typical direct diagnosis algorithm that supports diagnosis calculation without pre-determining conflicts. However, this approach faces runtime performance issues, especially when analyzing complex and large-scale knowledge bases. In this paper, we propose a novel algorithm, so-called FastDiagP, which is based on the idea of speculative programming. This algorithm extends FastDiag by integrating a parallelization mechanism that anticipates and pre-calculates consistency checks requested by FastDiag. This mechanism helps to provide consistency checks with fast answers and boosts the algorithmâ€™s runtime performance. The performance improvements of our proposed algorithm have been shown through empirical results using the Linux-2.6.3.33 configuration knowledge base.","[""KRR: Diagnosis and Abductive Reasoning"", ""CSO: Applications"", ""KRR: Applications"", ""KRR: Knowledge Engineering""]","[""Viet-Man Le"", ""Cristian Vidal Silva"", ""Alexander Felfernig"", ""David Benavides"", ""Jos\u00e9 Galindo"", ""Thi Ngoc Trang Tran""]",https://ojs.aaai.org/index.php/AAAI/article/view/25792/25564,AAAI
Self-Paced Learning Based Graph Convolutional Neural Network for Mixed Integer Programming (Student Abstract),"Graph convolutional neural network (GCN) based methods have achieved noticeable performance in solving mixed integer programming problems (MIPs). However, the generalization of existing work is limited due to the problem structure. This paper proposes a self-paced learning (SPL) based GCN network (SPGCN) with curriculum learning (CL) to make the utmost of samples. SPGCN employs a GCN model to imitate the branching variable selection during the branch and bound process, while the training process is conducted in a self-paced fashion. Specifically, SPGCN contains a loss-based automatic difficulty measurer, where the training loss of the sample represents the difficulty level. In each iteration, a dynamic training dataset is constructed according to the difficulty level for GCN model training. Experiments on four NP-hard datasets verify that CL can lead to generalization improvement and convergence speedup in solving MIPs, where SPL performs better than predefined CL methods.","[""Mixed Integer Programming Problems"", ""Graph Convolutional Neural Network"", ""Curriculum Learning""]","[""Li Chen"", ""Hua Xu"", ""Ziteng Wang"", ""Chengming Wang"", ""Yu Jiang""]",https://ojs.aaai.org/index.php/AAAI/article/view/26954/26726,AAAI
Adaptive Temporal Planning for Multi-Robot Systems in Operations and Maintenance of Offshore Wind Farms,"With the fast development of offshore wind farms as renewable energy sources, maintaining them efficiently and safely becomes necessary. The high costs of operation and maintenance (O&M) are due to the length of turbine downtime and the logistics for human technician transfer. To reduce such costs, we propose a comprehensive multi-robot system that includes unmanned aerial vehicles (UAV), autonomous surface vessels (ASV), and inspection-and-repair robots (IRR). Our system, which is capable of co-managing the farms with human operators located onshore, brings down costs and significantly reduces the Health and Safety (H&S) risks of O&M by assisting human operators in performing dangerous tasks. In this paper, we focus on using AI temporal planning to coordinate the actions of the different autonomous robots that form the multi-robot system. We devise a new, adaptive planning approach that reduces failures and replanning by performing data-driven goal and domain refinement. Our experiments in both simulated and real-world scenarios prove the effectiveness and robustness of our technique. The success of our system marks the first-step towards a large-scale, multirobot solution for wind farm O&M.","[""PDDL"", ""Adaptive Planning"", ""Multi-Agent Planning"", ""Extreme Environments""]","[""Ferdian Jovan"", ""Sara Bernardini""]",https://ojs.aaai.org/index.php/AAAI/article/view/26874/26646,AAAI
Testing the Channels of Convolutional Neural Networks,"Neural networks have complex structures, and thus it is hard to understand their inner workings and ensure correctness. To understand and debug convolutional neural networks (CNNs) we propose techniques for testing the channels of CNNs. We design FtGAN, an extension to GAN, that can generate test data with varying the intensity (i.e., sum of the neurons) of a channel of a target CNN. We also proposed a channel selection algorithm to find representative channels for testing. To efficiently inspect the target CNNâ€™s inference computations, we define unexpectedness score, which estimates how similar the inference computation of the test data is to that of the training data. We evaluated FtGAN with five public datasets and showed that our techniques successfully identify defective channels in five different CNN models.","[""General""]","[""Kang Choi"", ""Donghyun Son"", ""Younghoon Kim"", ""Jiwon Seo""]",https://ojs.aaai.org/index.php/AAAI/article/view/26726/26498,AAAI
Improvement-Focused Causal Recourse (ICR),"Algorithmic recourse recommendations inform stakeholders of how to act to revert unfavorable decisions. However, existing methods may recommend actions that lead to acceptance (i.e., revert the model's decision) but do not lead to improvement (i.e., may not revert the underlying real-world state). To recommend such actions is to recommend fooling the predictor. We introduce a novel method, Improvement-Focused Causal Recourse (ICR), which involves a conceptual shift: Firstly, we require ICR recommendations to guide toward improvement. Secondly, we do not tailor the recommendations to be accepted by a specific predictor.  Instead, we leverage causal knowledge to design decision systems that predict accurately pre- and post-recourse, such that improvement guarantees translate into acceptance guarantees. Curiously, optimal pre-recourse classifiers are robust to ICR actions and thus suitable post-recourse. In semi-synthetic experiments, we demonstrate that given correct causal knowledge ICR, in contrast to existing approaches, guides toward both acceptance and improvement.","[""PEAI: Interpretability and Explainability"", ""ML: Causal Learning"", ""PEAI: Philosophical Foundations of AI"", ""RU: Causality"", ""RU: Graphical Model""]","[""Gunnar K\u00f6nig"", ""Timo Freiesleben"", ""Moritz Grosse-Wentrup""]",https://ojs.aaai.org/index.php/AAAI/article/view/26398/26170,AAAI
The Parameterized Complexity of Network Microaggregation,"Microaggregation is a classical statistical disclosure control technique which requires the input data to be partitioned into clusters while adhering to specified size constraints. We provide novel exact algorithms and lower bounds for the task of microaggregating a given network while considering both unrestricted and connected clusterings, and analyze these from the perspective of the parameterized complexity paradigm. Altogether, our results assemble a complete complexity-theoretic picture for the network microaggregation problem with respect to the most natural parameterizations of the problem, including input-specified parameters capturing the size and homogeneity of the clusters as well as the treewidth and vertex cover number of the network.","[""KRR: Computational Complexity of Reasoning"", ""CSO: Other Foundations of Constraint Satisfaction & Optimization"", ""DMKM: Graph Mining"", ""Social Network Analysis & Community Mining"", ""GTEP: Other Foundations of Game Theory & Economic Paradigms"", ""ML: Clustering""]","[""V\u00e1clav Bla\u017eej"", ""Robert Ganian"", ""Du\u0161an Knop"", ""Jan Pokorn\u00fd"", ""\u0160imon Schierreich"", ""Kirill Simonov""]",https://ojs.aaai.org/index.php/AAAI/article/view/25771/25543,AAAI
Graph Knows Unknowns: Reformulate Zero-Shot Learning as Sample-Level Graph Recognition,"Zero-shot learning (ZSL) is an extreme case of transfer learning that aims to recognize samples (e.g., images) of unseen classes relying on a train-set covering only seen classes and a set of auxiliary knowledge (e.g., semantic descriptors). Existing methods usually resort to constructing a visual-to-semantics mapping based on features extracted from each whole sample. However, since the visual and semantic spaces are inherently independent and may exist in different manifolds, these methods may easily suffer from the domain bias problem due to the knowledge transfer from seen to unseen classes. Unlike existing works, this paper investigates the fine-grained ZSL from a novel perspective of sample-level graph. Specifically, we decompose an input into several fine-grained elements and construct a graph structure per sample to measure and utilize element-granularity relations within each sample. Taking advantage of recently developed graph neural networks (GNNs), we formulate the ZSL problem to a graph-to-semantics mapping task, which can better exploit element-semantics correlation and local sub-structural information in samples. Experimental results on the widely used benchmark datasets demonstrate that the proposed method can mitigate the domain bias problem and achieve competitive performance against other representative methods.","[""ML: Transfer"", ""Domain Adaptation"", ""Multi-Task Learning"", ""ML: Applications"", ""ML: Classification and Regression"", ""ML: Representation Learning""]","[""Jingcai Guo"", ""Song Guo"", ""Qihua Zhou"", ""Ziming Liu"", ""Xiaocheng Lu"", ""Fushuo Huo""]",https://ojs.aaai.org/index.php/AAAI/article/view/25942/25714,AAAI
Extracting Semantic-Dynamic Features for Long-Term Stable Brain Computer Interface,"Brain-computer Interface (BCI) builds a neural signal to the motor command pathway, which is a prerequisite for the realization of neural prosthetics. However, a long-term stable BCI suffers from the neural data drift across days while retraining the BCI decoder is expensive and restricts its application scenarios. Recent solutions of neural signal recalibration treat the continuous neural signals as discrete, which is less effective in temporal feature extraction. Inspired by the observation from biologists that low-dimensional dynamics could describe high-dimensional neural signals, we model the underlying neural dynamics and propose a semantic-dynamic feature that represents the semantics and dynamics in a shared feature space facilitating the BCI recalibration. Besides, we present the joint distribution alignment instead of the common used marginal alignment strategy, dealing with the various complex changes in neural data distribution. Our recalibration approach achieves state-of-the-art performance on the real neural data of two monkeys in both classification and regression tasks. Our approach is also evaluated on a simulated dataset, which indicates its robustness in dealing with various common causes of neural signal instability.","[""HAI: Brain-Sensing and Analysis"", ""HAI: Applications""]","[""Tao Fang"", ""Qian Zheng"", ""Yu Qi"", ""Gang Pan""]",https://ojs.aaai.org/index.php/AAAI/article/view/25738/25510,AAAI
SR-AnoGAN: You Never Detect Alone. Super Resolution in Anomaly Detection (Student Abstract),"Despite the advance in deep learning algorithms, implementing supervised learning algorithms in medical datasets is difficult owing to the medical data's properties. This paper proposes SR-AnoGAN, which could generate higher resolution images and conduct anomaly detection more efficiently than AnoGAN. The most distinctive part of the proposed model is incorporating CNN and SRGAN into AnoGAN for reconstructing high-resolution images. Experimental results from X-ray datasets(pneumonia, covid-19) verify that the SR-AnoGAN outperforms the previous AnoGAN model through qualitative and quantitative approaches. Therefore, this paper shows the possibility of resolving data imbalance problems prevalent in the medical field, and proposing more precise diagnosis.","[""Deep Learning"", ""Anomaly Detection"", ""GAN"", ""Unsupervised Learning"", ""X-ray""]","[""Minjong Cheon""]",https://ojs.aaai.org/index.php/AAAI/article/view/26957/26729,AAAI
Fast Converging Anytime Model Counting,"Model counting is a fundamental problem which has been influential in many applications, from artificial intelligence to formal verification. Due to the intrinsic hardness of model counting, approximate techniques have been developed to solve real-world instances of model counting. This paper designs a new anytime approach called PartialKC for approximate model counting. The idea is a form of partial knowledge compilation to provide an unbiased estimate of the model count which can converge to the exact count. Our empirical analysis demonstrates that PartialKC achieves significant scalability and accuracy over prior state-of-the-art approximate counters, including satss and STS. Interestingly, the empirical results show that PartialKC reaches convergence for many instances and therefore provides exact model counting performance comparable to state-of-the-art exact counters.","[""CSO: Solvers and Tools"", ""CSO: Satisfiability"", ""KRR: Automated Reasoning and Theorem Proving"", ""RU: Other Foundations of Reasoning Under Uncertainty"", ""SO: Sampling/Simulation-Based Search""]","[""Yong Lai"", ""Kuldeep S. Meel"", ""Roland H.C. Yap""]",https://ojs.aaai.org/index.php/AAAI/article/view/25517/25289,AAAI
Human-in-the-Loop Vehicle ReID,"Vehicle ReID has been an active topic in computer vision, with a substantial number of deep neural models proposed as end-to-end solutions. In this paper, we solve the problem from a new perspective and present an interesting variant called human-in-the-loop vehicle ReID to leverage interactive (and possibly wrong) human feedback signal for performance enhancement. Such human-machine cooperation mode is orthogonal to existing ReID models. To avoid incremental training overhead, we propose an Interaction ReID Network (IRIN) that can directly accept the feedback signal as an input and adjust the embedding of query image in an online fashion. IRIN is offline trained by simulating the human interaction process, with multiple optimization strategies to fully exploit the feedback signal. Experimental results show that even by interacting  with flawed feedback generated by non-experts, IRIN still outperforms state-of-the-art ReID models by a considerable margin. If the feedback contains no false positive, IRIN boosts the mAP in Veri776 from 81.6% to 95.2% with only 5 rounds of interaction per query image.","[""HAI: Human-in-the-Loop Machine Learning"", ""CV: Applications"", ""CV: Image and Video Retrieval""]","[""Zepeng Li"", ""Dongxiang Zhang"", ""Yanyan Shen"", ""Gang Chen""]",https://ojs.aaai.org/index.php/AAAI/article/view/25747/25519,AAAI
Layout-Aware Dreamer for Embodied Visual Referring Expression Grounding,"In this work, we study the problem of Embodied Referring Expression Grounding, where an agent needs to navigate in a previously unseen environment and localize a remote object described by a concise high-level natural language instruction. When facing such a situation, a human tends to imagine what the destination may look like and to explore the environment based on prior knowledge of the environmental layout, such as the fact that a bathroom is more likely to be found near a bedroom than a kitchen. We have designed an autonomous agent called Layout-aware Dreamer (LAD), including two novel modules, that is, the Layout Learner and the Goal Dreamer to mimic this cognitive decision process. The Layout Learner learns to infer the room category distribution of neighboring unexplored areas along the path for coarse layout estimation, which effectively introduces layout common sense of room-to-room transitions to our agent. To learn an effective exploration of the environment, the Goal Dreamer imagines the destination beforehand. Our agent achieves new state-of-the-art performance on the public leaderboard of REVERIE dataset in challenging unseen test environments with improvement on navigation success rate (SR) by 4.02% and remote grounding success (RGS) by 3.43% comparing to previous previous state of the art. The code
is released at https://github.com/zehao-wang/LAD.","[""CV: Language and Vision"", ""CV: Multi-modal Vision""]","[""Mingxiao Li"", ""Zehao Wang"", ""Tinne Tuytelaars"", ""Marie-Francine Moens""]",https://ojs.aaai.org/index.php/AAAI/article/view/25223/24995,AAAI
Incomplete Multi-View Multi-Label Learning via Label-Guided Masked View- and Category-Aware Transformers,"As we all know, multi-view data is more expressive than single-view data and multi-label annotation enjoys richer supervision information than single-label, which makes multi-view multi-label learning widely applicable for various pattern recognition tasks. In this complex representation learning problem, three main challenges can be characterized as follows: i) How to learn consistent representations of samples across all views? ii) How to exploit and utilize category correlations of multi-label to guide inference? iii) How to avoid the negative impact resulting from the incompleteness of views or labels? To cope with these problems, we propose a general multi-view multi-label learning framework named label-guided masked view- and category-aware transformers in this paper. First, we design two transformer-style based modules for cross-view features aggregation and multi-label classification, respectively. The former aggregates information from different views in the process of extracting view-specific features, and the latter learns subcategory embedding to improve classification performance. Second, considering the imbalance of expressive power among views, an adaptively weighted view fusion module is proposed to obtain view-consistent embedding features. Third, we impose a label manifold constraint in sample-level representation learning to maximize the utilization of supervised information. Last but not least, all the modules are designed under the premise of incomplete views and labels, which makes our method adaptable to arbitrary multi-view and multi-label data. Extensive experiments on five datasets confirm that our method has clear advantages over other state-of-the-art methods.","[""ML: Multi-Instance/Multi-View Learning"", ""ML: Multi-Class/Multi-Label Learning & Extreme Classification"", ""ML: Multimodal Learning"", ""ML: Representation Learning""]","[""Chengliang Liu"", ""Jie Wen"", ""Xiaoling Luo"", ""Yong Xu""]",https://ojs.aaai.org/index.php/AAAI/article/view/26060/25832,AAAI
Incremental Image De-raining via Associative Memory,"While deep learning models have achieved the state-of-the-art performance on single-image rain removal, most methods only consider learning fixed mapping rules on the single synthetic dataset for lifetime. This limits the real-life application as iterative optimization may change mapping rules and training samples. However, when models learn a sequence of datasets in multiple incremental steps, they are susceptible to catastrophic forgetting that adapts to new incremental episodes while failing to preserve previously acquired mapping rules. In this paper, we argue the importance of sample diversity in the episodes on the iterative optimization, and propose a novel memory management method, Associative Memory, to achieve incremental image de-raining. It bridges connections between current and past episodes for feature reconstruction by sampling domain mappings of past learning steps, and guides the learning to trace the current pathway back to the historical environment without storing extra data. Experiments demonstrate that our method can achieve better performance than existing approaches on both inhomogeneous and incremental datasets within the spectrum of highly compact systems.","[""CV: Computational Photography"", ""Image & Video Synthesis""]","[""Yi Gu"", ""Chao Wang"", ""Jie Li""]",https://ojs.aaai.org/index.php/AAAI/article/view/25145/24917,AAAI
Generating Transferable 3D Adversarial Point Cloud via Random Perturbation Factorization,"Recent studies have demonstrated that existing deep neural networks (DNNs) on 3D point clouds are vulnerable to adversarial examples, especially under the white-box settings where the adversaries have access to model parameters. However, adversarial 3D point clouds generated by existing white-box methods have limited transferability across different DNN architectures. They have only minor threats in real-world scenarios under the black-box settings where the adversaries can only query the deployed victim model. In this paper, we revisit the transferability of adversarial 3D point clouds. We observe that an adversarial perturbation can be randomly factorized into two sub-perturbations, which are also likely to be adversarial perturbations. It motivates us to consider the effects of the perturbation and its sub-perturbations simultaneously to increase the transferability for sub-perturbations also contain helpful information. In this paper, we propose a simple yet effective attack method to generate more transferable adversarial 3D point clouds. Specifically, rather than simply optimizing the loss of perturbation alone, we combine it with its random factorization. We conduct experiments on benchmark dataset, verifying our method's effectiveness in increasing transferability while preserving high efficiency.","[""CV: 3D Computer Vision"", ""CV: Bias"", ""Fairness & Privacy"", ""CV: Adversarial Attacks & Robustness""]","[""Bangyan He"", ""Jian Liu"", ""Yiming Li"", ""Siyuan Liang"", ""Jingzhi Li"", ""Xiaojun Jia"", ""Xiaochun Cao""]",https://ojs.aaai.org/index.php/AAAI/article/view/25154/24926,AAAI
Wiener Graph Deconvolutional Network Improves Graph Self-Supervised Learning,"Graph self-supervised learning (SSL) has been vastly employed to learn representations from unlabeled graphs. Existing methods can be roughly divided into predictive learning and contrastive learning, where the latter one attracts more research attention with better empirical performance. We argue that, however, predictive models weaponed with powerful decoder could achieve comparable or even better representation power than contrastive models. In this work, we propose a Wiener Graph Deconvolutional Network (WGDN), an augmentation-adaptive decoder empowered by graph wiener filter to perform information reconstruction. Theoretical analysis proves the superior reconstruction ability of graph wiener filter. Extensive experimental results on various datasets demonstrate the effectiveness of our approach.","[""ML: Graph-based Machine Learning"", ""ML: Unsupervised & Self-Supervised Learning""]","[""Jiashun Cheng"", ""Man Li"", ""Jia Li"", ""Fugee Tsung""]",https://ojs.aaai.org/index.php/AAAI/article/view/25870/25642,AAAI
"Script, Language, and Labels: Overcoming Three Discrepancies for Low-Resource Language Specialization","Although multilingual pretrained models (mPLMs) enabled support of various natural language processing in diverse languages, its limited coverage of 100+ languages lets 6500+ languages remain â€˜unseenâ€? One common approach for an unseen language is specializing the model for it as target, by performing additional masked language modeling (MLM) with the target language corpus. However, we argue that, due to the discrepancy from multilingual MLM pretraining, a naive specialization as such can be suboptimal. Specifically, we pose three discrepancies to overcome. Script and linguistic discrepancy of the target language from the related seen languages, hinder a positive transfer, for which we propose to maximize representation similarity, unlike existing approaches maximizing overlaps. In addition, label space for MLM prediction can vary across languages, for which we propose to reinitialize top layers for a more effective adaptation. Experiments over four different language families and three tasks shows that our method improves the task performance of unseen languages with statistical significance, while previous approach fails to.","[""SNLP: Machine Translation & Multilinguality"", ""SNLP: Language Models"", ""SNLP: Learning & Optimization for SNLP"", ""SNLP: Syntax -- Tagging"", ""Chunking & Parsing""]","[""Jaeseong Lee"", ""Dohyeon Lee"", ""Seung-won Hwang""]",https://ojs.aaai.org/index.php/AAAI/article/view/26528/26300,AAAI
Practical Parallel Algorithms for Submodular Maximization Subject to a Knapsack Constraint with Nearly Optimal Adaptivity,"Submodular maximization has wide applications in machine learning and data mining, where massive datasets have brought the great need for designing efficient and parallelizable algorithms. One measure of the parallelizability of a submodular maximization algorithm is its adaptivity complexity, which indicates the number of sequential rounds where a polynomial number of queries to the objective function can be executed in parallel. In this paper, we study the problem of non-monotone submodular maximization subject to a knapsack constraint, and propose the first combinatorial algorithm achieving an (8+epsilon)-approximation under O(log n) adaptive complexity, which is optimal up to a factor of O(loglog n). Moreover, under slightly larger adaptivity, we also propose approximation algorithms with nearly optimal query complexity of O(n), while achieving better approximation ratios. We show that our algorithms can also be applied to the special case of submodular maximization subject to a cardinality constraint, and achieve performance bounds comparable with those of state-of-the-art algorithms. Finally, the effectiveness of our approach is demonstrated by extensive experiments on real-world applications.","[""ML: Optimization""]","[""Shuang Cui"", ""Kai Han"", ""Jing Tang"", ""He Huang"", ""Xueying Li"", ""Aakas Zhiyuli""]",https://ojs.aaai.org/index.php/AAAI/article/view/25885/25657,AAAI
Local Justice and Machine Learning: Modeling and Inferring Dynamic Ethical Preferences toward Allocations,"We consider a setting in which a social planner has to make a sequence of decisions to allocate scarce resources in a high-stakes domain. Our goal is to understand stakeholders' dynamic moral preferences toward such allocational policies. In particular, we evaluate the sensitivity of moral preferences to the history of allocations and their perceived future impact on various socially salient groups.  We propose a mathematical model to capture and infer such dynamic moral preferences. We illustrate our model through small-scale human-subject experiments focused on the allocation of scarce medical resource distributions during a hypothetical viral epidemic. We observe that participants' preferences are indeed history- and impact-dependent. Additionally, our preliminary experimental results reveal intriguing patterns specific to medical resources---a topic that is particularly salient against the backdrop of the global covid-19 pandemic.","[""HAI: Learning Human Values and Preferences"", ""PEAI: Bias"", ""Fairness & Equity""]","[""Violet (Xinying) Chen"", ""Joshua Williams"", ""Derek Leben"", ""Hoda Heidari""]",https://ojs.aaai.org/index.php/AAAI/article/view/25737/25509,AAAI
Generalized Category Discovery with Decoupled Prototypical Network,"Generalized Category Discovery (GCD) aims to recognize both known and novel categories from a set of unlabeled data, based on another dataset labeled with only known categories. Without considering differences between known and novel categories, current methods learn about them in a coupled manner, which can hurt model's generalization and discriminative ability. Furthermore, the coupled training approach prevents these models transferring category-specific knowledge explicitly from labeled data to unlabeled data, which can lose high-level semantic information and impair model performance. To mitigate above limitations, we present a novel model called Decoupled Prototypical Network (DPN). By formulating a bipartite matching problem for category prototypes, DPN can not only decouple known and novel categories to achieve different training targets effectively, but also align known categories in labeled and unlabeled data to transfer category-specific knowledge explicitly and capture high-level semantics. Furthermore, DPN can learn more discriminative features for both known and novel categories through our proposed Semantic-aware Prototypical Learning (SPL). Besides capturing meaningful semantic information, SPL can also alleviate the noise of hard pseudo labels through semantic-weighted soft assignment. Extensive experiments show that DPN outperforms state-of-the-art models by a large margin on all evaluation metrics across multiple benchmark datasets. Code and data are available at https://github.com/Lackel/DPN.","[""SNLP: Text Mining"", ""SNLP: Text Classification""]","[""Wenbin An"", ""Feng Tian"", ""Qinghua Zheng"", ""Wei Ding"", ""Qianying Wang"", ""Ping Chen""]",https://ojs.aaai.org/index.php/AAAI/article/view/26475/26247,AAAI
Poisoning-Based Backdoor Attacks in Computer Vision,"Recent studies demonstrated that the training process of deep neural networks (DNNs) is vulnerable to backdoor attacks if third-party training resources (e.g., samples) are adopted. Specifically, the adversaries intend to embed hidden backdoors into DNNs, where the backdoor can be activated by pre-defined trigger patterns and leading malicious model predictions. My dissertation focuses on poisoning-based backdoor attacks in computer vision. Firstly, I study and propose more stealthy and effective attacks against image classification tasks in both physical and digital spaces. Secondly, I reveal the backdoor threats in visual object tracking, which is representative of critical video-related tasks. Thirdly, I explore how to exploit backdoor attacks as watermark techniques for positive purposes. I design a Python toolbox (i.e., BackdoorBox) that implements representative and advanced backdoor attacks and defenses under a unified and flexible framework, based on which to provide a comprehensive benchmark of existing methods at the end.","[""Backdoor Attack"", ""Backdoor Learning"", ""Data Poisoning"", ""Trustworthy ML"", ""AI Security""]","[""Yiming Li""]",https://ojs.aaai.org/index.php/AAAI/article/view/26921/26693,AAAI
Disentangling the Benefits of Self-Supervised Learning to Deployment-Driven Downstream Tasks of Satellite Images (Student Abstract),"In this paper, we investigate the benefits of self-supervised learning (SSL) to downstream tasks of satellite images. Unlike common student academic projects, this work focuses on the advantages of the SSL for deployment-driven tasks which have specific scenarios with low or high-spatial resolution images. Our preliminary experiments demonstrate the robust benefits of the SSL trained by medium-resolution (10m) images to both low-resolution (100m) scene classification case (4.25%â†? and very high-resolution (5cm) aerial image segmentation case (1.96%â†?, respectively.","[""Self-supervised Learning"", ""Satellite Image"", ""Deployment-driven""]","[""Zhuo Deng"", ""Yibing Wei"", ""Mingye Zhu"", ""Xueliang Wang"", ""Junchi Zhou"", ""Zhicheng Yang"", ""Hang Zhou"", ""Zhenjie Cao"", ""Lan Ma"", ""Mei Han"", ""Jui-Hsin Lai""]",https://ojs.aaai.org/index.php/AAAI/article/view/26959/26731,AAAI
Formalising the Robustness of Counterfactual Explanations for Neural Networks,"The use of counterfactual explanations (CFXs) is an increasingly popular explanation strategy for machine learning models. However, recent studies have shown that these explanations may not be robust to changes in the underlying model (e.g., following retraining), which raises questions about their reliability in real-world applications. Existing attempts towards solving this problem are heuristic, and the robustness to model changes of the resulting CFXs is evaluated with only a small number of retrained models, failing to provide exhaustive guarantees. To remedy this, we propose âˆ?robustness, the first notion to formally and deterministically assess the robustness (to model changes) of CFXs for neural networks. We introduce an abstraction framework based on interval neural networks
to verify the âˆ?robustness of CFXs against a possibly infinite set of changes to the model parameters, i.e., weights and biases. We then demonstrate the utility of this approach in two distinct ways. First, we  analyse the âˆ?robustness of a number of CFX generation methods from the literature and show that they unanimously host significant deficiencies in this regard. Second, we demonstrate how embedding âˆ?robustness within existing methods can provide CFXs which are provably robust.","[""General""]","[""Junqi Jiang"", ""Francesco Leofante"", ""Antonio Rago"", ""Francesca Toni""]",https://ojs.aaai.org/index.php/AAAI/article/view/26740/26512,AAAI
Feature Distribution Fitting with Direction-Driven Weighting for Few-Shot Images Classification,"Few-shot learning has received increasing attention and witnessed significant advances in recent years. However, most of the few-shot learning methods focus on the optimization of training process, and the learning of metric and sample generating networks. They ignore the importance of learning the ground-truth feature distributions of few-shot classes. This paper proposes a direction-driven weighting method to make the feature distributions of few-shot classes precisely fit the ground-truth distributions. The learned feature distributions can generate an unlimited number of training samples for the few-shot classes to avoid overfitting. Specifically, the proposed method consists of two optimization strategies. The direction-driven strategy is for capturing more complete direction information that can describe the feature distributions. The similarity-weighting strategy is proposed to estimate the impact of different classes in the fitting procedure and assign corresponding weights. Our method outperforms the current state-of-the-art performance by an average of 3% for 1-shot on standard few-shot learning benchmarks like miniImageNet, CIFAR-FS, and CUB. The excellent performance and compelling visualization show that our method can more accurately estimate the ground-truth distributions.","[""ML: Classification and Regression"", ""ML: Deep Generative Models & Autoencoders"", ""ML: Deep Neural Network Algorithms""]","[""Xin Wei"", ""Wei Du"", ""Huan Wan"", ""Weidong Min""]",https://ojs.aaai.org/index.php/AAAI/article/view/26228/26000,AAAI
Domain-Adapted Dependency Parsing for Cross-Domain Named Entity Recognition,"In recent years, many researchers have leveraged structural information from dependency trees to improve Named Entity Recognition (NER). Most of their methods take dependency-tree labels as input features for NER model training. However, such dependency information is not inherently provided in most NER corpora, making the methods with low usability in practice. To effectively exploit the potential of word-dependency knowledge, motivated by the success of Multi-Task Learning on cross-domain NER, we investigate a novel NER learning method incorporating cross-domain Dependency Parsing (DP) as its auxiliary learning task. Then, considering the high consistency of word-dependency relations across domains, we present an unsupervised domain-adapted method to transfer word-dependency knowledge from high-resource domains to low-resource ones. With the help of cross-domain DP to bridge different domains, both useful cross-domain and cross-task knowledge can be learned by our model to considerably benefit cross-domain NER. To make better use of the cross-task knowledge between NER and DP, we unify both tasks in a shared network architecture for joint learning, using Maximum Mean Discrepancy(MMD). Finally, through extensive experiments, we show our proposed method can not only effectively take advantage of word-dependency knowledge, but also significantly outperform other Multi-Task Learning methods on cross-domain NER. Our code is open-source and available at https://github.com/xianghuisun/DADP.","[""SNLP: Syntax -- Tagging"", ""Chunking & Parsing"", ""SNLP: Lexical & Frame Semantics"", ""Semantic Parsing"", ""SNLP: Other Foundations of Speech & Natural Language Processing"", ""SNLP: Phonology"", ""Morphology"", ""Word Segmentation"", ""SNLP: Text Mining""]","[""Chenxiao Dou"", ""Xianghui Sun"", ""Yaoshu Wang"", ""Yunjie Ji"", ""Baochang Ma"", ""Xiangang Li""]",https://ojs.aaai.org/index.php/AAAI/article/view/26498/26270,AAAI
NewsPanda: Media Monitoring for Timely Conservation Action,"Non-governmental organizations for environmental conservation have a significant interest in monitoring conservation-related media and getting timely updates about infrastructure construction projects as they may cause massive impact to key conservation areas. Such monitoring, however, is difficult and time-consuming. We introduce NewsPanda, a toolkit which automatically detects and analyzes online articles related to environmental conservation and infrastructure construction. We fine-tune a BERT-based model using active learning methods and noise correction algorithms to identify articles that are relevant to conservation and infrastructure construction. For the identified articles, we perform further analysis, extracting keywords and finding potentially related sources. NewsPanda has been successfully deployed by the World Wide Fund for Nature teams in the UK, India, and Nepal since February 2022. It currently monitors over 80,000 websites and 1,074 conservation sites across India and Nepal, saving more than 30 hours of human efforts weekly. We have now scaled it up to cover 60,000 conservation sites globally.","[""Conservation"", ""Infrastructure"", ""NLP""]","[""Sedrick Scott Keh"", ""Zheyuan Ryan Shi"", ""David J. Patterson"", ""Nirmal Bhagabati"", ""Karun Dewan"", ""Areendran Gopala"", ""Pablo Izquierdo"", ""Debojyoti Mallick"", ""Ambika Sharma"", ""Pooja Shrestha"", ""Fei Fang""]",https://ojs.aaai.org/index.php/AAAI/article/view/26841/26613,AAAI
Fast Regularized Discrete Optimal Transport with Group-Sparse Regularizers,"Regularized discrete optimal transport (OT) is a powerful tool to measure the distance between two discrete distributions that have been constructed from data samples on two different domains. While it has a wide range of applications in machine learning, in some cases the sampled data from only one of the domains will have class labels such as unsupervised domain adaptation. In this kind of problem setting, a group-sparse regularizer is frequently leveraged as a regularization term to handle class labels. In particular, it can preserve the label structure on the data samples by corresponding the data samples with the same class label to one group-sparse regularization term. As a result, we can measure the distance while utilizing label information by solving the regularized optimization problem with gradient-based algorithms. However, the gradient computation is expensive when the number of classes or data samples is large because the number of regularization terms and their respective sizes also turn out to be large. This paper proposes fast discrete OT with group-sparse regularizers. Our method is based on two ideas. The first is to safely skip the computations of the gradients that must be zero. The second is to efficiently extract the gradients that are expected to be nonzero. Our method is guaranteed to return the same value of the objective function as that of the original approach. Experiments demonstrate that our method is up to 8.6 times faster than the original method without degrading accuracy.","[""ML: Optimization"", ""ML: Transfer"", ""Domain Adaptation"", ""Multi-Task Learning"", ""ML: Dimensionality Reduction/Feature Selection"", ""ML: Matrix & Tensor Methods""]","[""Yasutoshi Ida"", ""Sekitoshi Kanai"", ""Kazuki Adachi"", ""Atsutoshi Kumagai"", ""Yasuhiro Fujiwara""]",https://ojs.aaai.org/index.php/AAAI/article/view/25965/25737,AAAI
Accurate Fairness: Improving Individual Fairness without Trading Accuracy,"Accuracy and individual fairness are both crucial for trustworthy machine learning, but these two aspects are often incompatible with each other so that enhancing one aspect may sacrifice the other inevitably with side effects of true bias or false fairness. We propose in this paper a new fairness criterion, accurate fairness, to align individual fairness with accuracy. Informally, it requires the treatments of an individual and the individual's similar counterparts to conform to a uniform target, i.e., the ground truth of the individual. We prove that accurate fairness also implies typical group fairness criteria over a union of similar sub-populations. We then present a Siamese fairness in-processing approach to minimize the accuracy and fairness losses of a machine learning model under the accurate fairness constraints. To the best of our knowledge, this is the first time that a Siamese approach is adapted for bias mitigation. We also propose fairness confusion matrix-based metrics, fair-precision, fair-recall, and fair-F1 score, to quantify a trade-off between accuracy and individual fairness. Comparative case studies with popular fairness datasets show that our Siamese fairness approach can achieve on average 1.02%-8.78% higher individual fairness (in terms of fairness through awareness) and 8.38%-13.69% higher accuracy, as well as 10.09%-20.57% higher true fair rate, and 5.43%-10.01% higher fair-F1 score, than the state-of-the-art bias mitigation techniques. This demonstrates that our Siamese fairness approach can indeed improve individual fairness without trading accuracy. Finally, the accurate fairness criterion and Siamese fairness approach are applied to mitigate the possible service discrimination with a real Ctrip dataset, by on average fairly serving 112.33% more customers (specifically, 81.29% more customers in an accurately fair way) than baseline models.","[""General""]","[""Xuran Li"", ""Peng Wu"", ""Jing Su""]",https://ojs.aaai.org/index.php/AAAI/article/view/26674/26446,AAAI
Automatically Verifying Expressive Epistemic Properties of Programs,"We propose a new approach to the verification of epistemic properties of programmes. First, we introduce the new ``program-epistemic'' logic L_PK, which is strictly richer and more general than similar formalisms appearing in the literature. To solve the verification problem in an efficient way, we introduce a translation from our language L_PK into first-order logic. Then, we show and prove correct a reduction from the model checking problem for program-epistemic formulas to the satisfiability of their first-order translation. Both our logic and our translation can handle richer specification w.r.t. the state of the art, allowing us to express the knowledge of agents about facts pertaining to programs (i.e., agents' knowledge before a program is executed as well as after is has been executed). Furthermore, we implement our translation in Haskell in a general way (i.e., independently of the programs in the logical statements), and we use existing SMT-solvers to check satisfaction of L_PK formulas on a benchmark example in the AI/agency field.","[""KRR: Knowledge Representation Languages""]","[""Francesco Belardinelli"", ""Ioana Boureanu"", ""Vadim Malvone"", ""Fortunat Rajaona""]",https://ojs.aaai.org/index.php/AAAI/article/view/25769/25541,AAAI
Attribute and Structure Preserving Graph Contrastive Learning,"Graph Contrastive Learning (GCL) has drawn much research interest due to its strong ability to capture both graph structure and node attribute information in a self-supervised manner. Current GCL methods usually adopt Graph Neural Networks (GNNs) as the base encoder, which typically relies on the homophily assumption of networks and overlooks node similarity in the attribute space. There are many scenarios where such assumption cannot be satisfied, or node similarity plays a crucial role. In order to design a more robust mechanism, we develop a novel attribute and structure preserving graph contrastive learning framework, named ASP, which comprehensively and efficiently preserves node attributes while exploiting graph structure. Specifically, we consider three different graph views in our framework, i.e., original view, attribute view, and global structure view. Then, we perform contrastive learning across three views in a joint fashion, mining comprehensive graph information. We validate the effectiveness of the proposed framework on various real-world networks with different levels of homophily. The results demonstrate the superior performance of our model over the representative baselines.","[""ML: Graph-based Machine Learning"", ""ML: Unsupervised & Self-Supervised Learning"", ""ML: Representation Learning"", ""ML: Deep Neural Network Algorithms"", ""ML: Classification and Regression""]","[""Jialu Chen"", ""Gang Kou""]",https://ojs.aaai.org/index.php/AAAI/article/view/25858/25630,AAAI
Evaluating and Improving Interactions with Hazy Oracles,"Many AI systems integrate sensor inputs, world knowledge, and human-provided information to perform inference. While such systems often treat the human input as flawless, humans are better thought of as hazy oracles whose input may be ambiguous or outside of the AI system's understanding. In such situations it makes sense for the AI system to defer its inference while it disambiguates the human-provided information by, for example, asking the human to rephrase the query. Though this approach has been considered in the past, current work is typically limited to application-specific methods and non-standardized human experiments. We instead introduce and formalize a general notion of deferred inference. Using this formulation, we then propose a novel evaluation centered around the Deferred Error Volume (DEV) metric, which explicitly considers the tradeoff between error reduction and the additional human effort required to achieve it. We demonstrate this new formalization and an innovative deferred inference method on the disparate tasks of Single-Target Video Object Tracking and Referring Expression Comprehension, ultimately reducing error by up to 48% without any change to the underlying model or its parameters.","[""HAI: Human-Computer Interaction"", ""ML: Evaluation and Analysis (Machine Learning)""]","[""Stephan J. Lemmer"", ""Jason J. Corso""]",https://ojs.aaai.org/index.php/AAAI/article/view/25746/25518,AAAI
End-to-End Learning for Optimization via Constraint-Enforcing Approximators,"In many real-world applications, predictive methods are used to provide inputs for downstream optimization problems. It has been shown that using the downstream task-based objective to learn the intermediate predictive model is often better than using only intermediate task objectives, such as prediction error. The learning task in the former approach is referred to as end-to-end learning. The difficulty in end-to-end learning lies in differentiating through the optimization problem. Therefore, we propose a neural network architecture that can learn to approximately solve these optimization problems, particularly ensuring its output satisfies the feasibility constraints via alternate projections. We show these projections converge at a geometric rate to the exact projection. Our approach is more computationally efficient than existing methods as we do not need to solve the original optimization problem at each iteration. Furthermore, our approach can be applied to a wider range of optimization problems. We apply this to a shortest path problem for which the first stage forecasting problem is a computer vision task of predicting edge costs from terrain maps, a capacitated multi-product newsvendor problem, and a maximum matching problem. We show that this method out-performs existing approaches in terms of final task-based loss and training time.","[""ML: Optimization"", ""RU: Stochastic Optimization""]","[""Rares Cristian"", ""Pavithra Harsha"", ""Georgia Perakis"", ""Brian L Quanz"", ""Ioannis Spantidakis""]",https://ojs.aaai.org/index.php/AAAI/article/view/25884/25656,AAAI
Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval,"Vision-language alignment learning for video-text retrieval arouses a lot of attention in recent years. Most of the existing methods either transfer the knowledge of image-text pretraining model to video-text retrieval task without fully exploring the multi-modal information of videos, or simply fuse multi-modal features in a brute force manner without explicit guidance. In this paper, we integrate multi-modal information in an explicit manner by tagging, and use the tags as the anchors for better video-text alignment. Various pretrained experts are utilized for extracting the information of multiple modalities, including object, person, motion, audio, etc. To take full advantage of these information, we propose the TABLE (TAgging Before aLignmEnt) network, which consists of a visual encoder, a tag encoder, a text encoder, and a tag-guiding cross-modal encoder for jointly encoding multi-frame visual features and multi-modal tags information. Furthermore, to strengthen the interaction between video and text, we build a joint cross-modal encoder with the triplet input of [vision, tag, text] and perform two additional supervised tasks, Video Text Matching (VTM) and Masked Language Modeling (MLM). Extensive experimental results demonstrate that the TABLE model is capable of achieving State-Of-The-Art (SOTA) performance on various video-text retrieval benchmarks, including MSR-VTT, MSVD, LSMDC and DiDeMo.","[""CV: Image and Video Retrieval"", ""CV: Language and Vision"", ""CV: Multi-modal Vision"", ""CV: Representation Learning for Vision"", ""CV: Video Understanding & Activity Analysis""]","[""Yizhen Chen"", ""Jie Wang"", ""Lijian Lin"", ""Zhongang Qi"", ""Jin Ma"", ""Ying Shan""]",https://ojs.aaai.org/index.php/AAAI/article/view/25113/24885,AAAI
Data-Driven Machine Learning Models for a Multi-Objective Flapping Fin Unmanned Underwater Vehicle Control System,"Flapping-fin unmanned underwater vehicle (UUV) propulsion systems provide high maneuverability for naval tasks such as surveillance and terrain exploration. Recent work has explored the use of time-series neural network surrogate models to predict thrust from vehicle design and fin kinematics. We develop a search-based inverse model that leverages a kinematics-to-thrust neural network model for control system design. Our inverse model finds a set of fin kinematics with the multi-objective goal of reaching a target thrust and creating a smooth kinematic transition between flapping cycles. We demonstrate how a control system integrating this inverse model can make online, cycle-to-cycle adjustments to prioritize different system objectives.","[""Machine Learning"", ""Inverse Model"", ""Multi-objective Optimization"", ""Generalized Pattern Search"", ""Neural Network"", ""Control System"", ""Deep Learning"", ""Surrogate Model"", ""UUV"", ""Pattern Search"", ""Flapping Fin"", ""Time-series"", ""Gait To Thrust"", ""LSTM"", ""Online"", ""Time Series Modelling"", ""Raspberry Pi"", ""Hooke Jeeves Pattern Search"", ""Fin Kinematics""]","[""Julian Lee"", ""Kamal Viswanath"", ""Alisha Sharma"", ""Jason Geder"", ""Marius Pruessner"", ""Brian Zhou""]",https://ojs.aaai.org/index.php/AAAI/article/view/26863/26635,AAAI
COSMOS: Catching Out-of-Context Image Misuse Using Self-Supervised Learning,"Despite the recent attention to DeepFakes, one of the most prevalent ways to mislead audiences on social media is the use of unaltered images in a new but false context. We propose a new method that automatically highlights out-of-context image and text pairs, for assisting fact-checkers. Our key insight is to leverage the grounding of images with text to distinguish out-of-context scenarios that cannot be disambiguated with language alone. We propose a self-supervised training strategy where we only need a set of captioned images. At train time, our method learns to selectively align individual objects in an image with textual claims, without explicit supervision. At test time, we check if both captions correspond to the same object(s) in the image but are semantically different, which allows us to make fairly accurate out-of-context predictions. Our method achieves 85% out-of-context detection accuracy. To facilitate benchmarking of this task, we create a large-scale dataset of 200K images with 450K textual captions from a variety of news websites, blogs, and social media posts","[""General""]","[""Shivangi Aneja"", ""Chris Bregler"", ""Matthias Niessner""]",https://ojs.aaai.org/index.php/AAAI/article/view/26648/26420,AAAI
Progress and Limitations of Deep Networks to Recognize Objects in Unusual Poses,"Deep networks should be robust to rare events if they are to be successfully deployed in high-stakes real-world applications. Here we study the capability of deep networks to recognize objects in unusual poses. We create a synthetic dataset of images of objects in unusual orientations, and evaluate the robustness of a collection of 38 recent and competitive deep networks for image classification. We show that classifying these images is still a challenge for all networks tested, with an average accuracy drop of 29.5% compared to when the objects are presented
upright. This brittleness is largely unaffected by various design choices, such as training losses, architectures, dataset modalities, and data-augmentation schemes. However, networks trained on very large datasets substantially outperform others, with the best network testedâ€”Noisy Student trained on JFT-300Mâ€”showing a relatively small accuracy drop of only 14.5% on unusual poses. Nevertheless, a visual inspection of the failures of Noisy Student reveals a remaining gap in robustness with humans. Furthermore, combining multiple object transformationsâ€?D-rotations and scalingâ€”further degrades the performance of all networks. Our results provide another measurement of the robustness of deep networks to consider when using them in the real world. Code and datasets are available at https://github.com/amro-kamal/ObjectPose.","[""CV: Adversarial Attacks & Robustness"", ""CV: Scene Analysis & Understanding"", ""ML: Deep Neural Architectures""]","[""Amro Abbas"", ""St\u00e9phane Deny""]",https://ojs.aaai.org/index.php/AAAI/article/view/25087/24859,AAAI
Learning from Good Trajectories in Offline Multi-Agent Reinforcement Learning,"Offline multi-agent reinforcement learning (MARL) aims to learn effective multi-agent policies from pre-collected datasets, which is an important step toward the deployment of multi-agent systems in real-world applications. However, in practice, each individual behavior policy that generates multi-agent joint trajectories usually has a different level of how well it performs. e.g., an agent is a random policy while other agents are medium policies. In the cooperative game with global reward, one agent learned by existing offline MARL often inherits this random policy, jeopardizing the utility of the entire team. In this paper, we investigate offline MARL with explicit consideration on the diversity of agent-wise trajectories and propose a novel framework called Shared Individual Trajectories (SIT) to address this problem. Specifically, an attention-based reward decomposition network assigns the credit to each agent through a differentiable key-value memory mechanism in an offline manner. These decomposed credits are then used to reconstruct the joint offline datasets into prioritized experience replay with individual trajectories, thereafter agents can share their good trajectories and conservatively train their policies with a graph attention network (GAT) based critic. We evaluate our method in both discrete control (i.e., StarCraft II and multi-agent particle environment) and continuous control (i.e., multi-agent mujoco). The results indicate that our method achieves significantly better results in complex and mixed offline multi-agent datasets, especially when the difference of data quality between individual trajectories is large.","[""MAS: Multiagent Learning"", ""MAS: Coordination and Collaboration""]","[""Qi Tian"", ""Kun Kuang"", ""Furui Liu"", ""Baoxiang Wang""]",https://ojs.aaai.org/index.php/AAAI/article/view/26379/26151,AAAI
"EasyRec: An Easy-to-Use, Extendable and Efficient Framework for Building Industrial Recommendation Systems","We present EasyRec, an easy-to-use, extendable and efficient recommendation framework for building industrial recommendation systems. Our EasyRec framework is superior in the following aspects:first, EasyRec adopts a modular and pluggable design pattern to reduce the efforts to build custom models; second, EasyRec implements hyper-parameter optimization and feature selection algorithms to improve model performance automatically; third, EasyRec applies online learning to adapt to the ever-changing data distribution. The code is released: https://github.com/alibaba/EasyRec.","[""Recommedation Framework"", ""Hyperparameter Optimization"", ""Distributed Training"", ""Large Scale""]","[""Mengli Cheng"", ""Yue Gao"", ""Guoqiang Liu"", ""HongSheng Jin""]",https://ojs.aaai.org/index.php/AAAI/article/view/27065/26837,AAAI
Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints,"Predict+Optimize is a recently proposed framework which combines machine learning and constrained optimization, tackling optimization problems that contain parameters that are unknown at solving time. The goal is to predict the unknown parameters and use the estimates to solve for an estimated optimal solution to the optimization problem. However, all prior works have focused on the case where unknown parameters appear only in the optimization objective and not the constraints, for the simple reason that if the constraints were not known exactly, the estimated optimal solution might not even be feasible under the true parameters. The contributions of this paper are two-fold. First, we propose a novel and practically relevant framework for the Predict+Optimize setting, but with unknown parameters in both the objective and the constraints. We introduce the notion of a correction function, and an additional penalty term in the loss function, modelling practical scenarios where an estimated optimal solution can be modified into a feasible solution after the true parameters are revealed, but at an additional cost. Second, we propose a corresponding algorithmic approach for our framework, which handles all packing and covering linear programs. Our approach is inspired by the prior work of Mandi and Guns, though with crucial modifications and re-derivations for our very different setting. Experimentation demonstrates the superior empirical performance of our method over classical approaches.","[""CSO: Constraint Optimization"", ""CSO: Constraint Programming"", ""CSO: Other Foundations of Constraint Satisfaction & Optimization""]","[""Xinyi Hu"", ""Jasper C.H. Lee"", ""Jimmy H.M. Lee""]",https://ojs.aaai.org/index.php/AAAI/article/view/25513/25285,AAAI
Prompt-Augmented Linear Probing: Scaling beyond the Limit of Few-Shot In-Context Learners,"Through in-context learning (ICL), large-scale language models are effective few-shot learners without additional model fine-tuning.  However, the ICL performance does not scale well with the number of available training sample as it is limited by the inherent input length constraint of the underlying language model. Meanwhile, many studies have revealed that language models are also powerful feature extractors, allowing them to be utilized in a black-box manner and enabling the linear probing paradigm, where lightweight discriminators are trained on top of the pre-extracted input representations. This paper proposes prompt-augmented linear probing (PALP), a hybrid of linear probing and ICL, which leverages the best of both worlds. PALP inherits the scalability of linear probing and the capability of enforcing language models to derive more meaningful representations via tailoring input into a more conceivable form. Throughout in-depth investigations on various datasets, we verified that PALP significantly closes the gap between ICL in the data-hungry scenario and fine-tuning in the data-abundant scenario with little training overhead, potentially making PALP a strong alternative in a black-box scenario.","[""SNLP: Language Models"", ""SNLP: Text Classification""]","[""Hyunsoo Cho"", ""Hyuhng Joon Kim"", ""Junyeob Kim"", ""Sang-Woo Lee"", ""Sang-goo Lee"", ""Kang Min Yoo"", ""Taeuk Kim""]",https://ojs.aaai.org/index.php/AAAI/article/view/26495/26267,AAAI
Second-Order Quantified Boolean Logic,"Second-order quantified Boolean formulas (SOQBFs) generalize quantified Boolean formulas (QBFs) by admitting second-order quantifiers on function variables in addition to first-order quantifiers on atomic variables. Recent endeavors establish that the complexity of SOQBF satisfiability corresponds to the exponential-time hierarchy (EXPH), similar to that of QBF satisfiability corresponding to the polynomial-time hierarchy (PH). This fact reveals the succinct expression power of SOQBFs in encoding decision problems not efficiently doable by QBFs. In this paper, we investigate the second-order quantified Boolean logic with the following main results: First, we present a procedure of quantifier elimination converting SOQBFs to QBFs and a game interpretation of SOQBF semantics. Second, we devise a sound and complete refutation-proof system for SOQBF. Third, we develop an algorithm for countermodel extraction from a refutation proof. Finally, we show potential applications of SOQBFs in system design and multi-agent planning. With these advances, we anticipate practical tools for development.","[""CSO: Other Foundations of Constraint Satisfaction & Optimization"", ""CSO: Constraint Satisfaction"", ""CSO: Satisfiability"", ""KRR: Automated Reasoning and Theorem Proving"", ""KRR: Computational Complexity of Reasoning"", ""KRR: Other Foundations of Knowledge Representation & Reasoning""]","[""Jie-Hong R. Jiang""]",https://ojs.aaai.org/index.php/AAAI/article/view/25515/25287,AAAI
Interactive Concept Bottleneck Models,"Concept bottleneck models (CBMs) are interpretable neural networks that first predict labels for human-interpretable concepts relevant to the prediction task, and then predict the final label based on the concept label predictions. We extend CBMs to interactive prediction settings where the model can query a human collaborator for the label to some concepts. We develop an interaction policy that, at prediction time, chooses which concepts to request a label for so as to maximally improve the final prediction. We demonstrate that a simple policy combining concept prediction uncertainty and influence of the concept on the final prediction achieves strong performance and outperforms static approaches as well as active feature acquisition methods proposed in the literature. We show that the interactive CBM can achieve accuracy gains of 5-10% with only 5 interactions over competitive baselines on the Caltech-UCSD Birds, CheXpert and OAI datasets.","[""HAI: Human-Machine Teams"", ""CV: Applications"", ""CV: Interpretability and Transparency"", ""HAI: Human-Computer Interaction"", ""ML: Calibration & Uncertainty Quantification"", ""ML: Transparent"", ""Interpretable"", ""Explainable ML"", ""RU: Applications""]","[""Kushal Chauhan"", ""Rishabh Tiwari"", ""Jan Freyberg"", ""Pradeep Shenoy"", ""Krishnamurthy Dvijotham""]",https://ojs.aaai.org/index.php/AAAI/article/view/25736/25508,AAAI
Exploring Artificial Intelligence in English Language Arts with StoryQ,"Exploring Artificial Intelligence (AI) in English Language Arts (ELA) with StoryQ is a 10-hour curriculum module designed for high school ELA classes. The module introduces students to fundamental AI concepts and essential machine learning workflow using StoryQ, a web-based GUI environment for Grades 6-12 learners. In this module, students work with unstructured text data and learn to train, test, and improve text classification models such as intent recognition, clickbait filter, and sentiment analysis. As they interact with machine-learning language models deeply, students also gain a nuanced understanding of language and how to wield it, not just as a data structure, but as a tool in our human-human encounters as well. The current version contains eight lessons, all delivered through a full-featured online learning and teaching platform. Computers and Internet access are required to implement the module. The module was piloted in an ELA class in the Spring of 2022, and the student learning outcomes were positive. The module is currently undergoing revision and will be further tested and improved in Fall 2022.","[""Machine Learning"", ""K-12 AI Education"", ""High School"", ""English Language Arts"", ""Curriculum Module"", ""Learning Technology"", ""Text Classification""]","[""Jie Chao"", ""Rebecca Ellis"", ""Shiyan Jiang"", ""Carolyn Ros\u00e9"", ""William Finzer"", ""Cansu Tatar"", ""James Fiacco"", ""Kenia Wiedemann""]",https://ojs.aaai.org/index.php/AAAI/article/view/26899/26671,AAAI
KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion,"Unpaired 3D object completion aims to predict a complete 3D shape from an incomplete input without knowing the correspondence between the complete and incomplete shapes. In this paper, we propose the novel KTNet to solve this task from the new perspective of knowledge transfer. KTNet elaborates a teacher-assistant-student network to establish multiple knowledge transfer processes. Specifically, the teacher network takes complete shape as input and learns the knowledge of complete shape. The student network takes the incomplete one as input and restores the corresponding complete shape. And the assistant modules not only help to transfer the knowledge of complete shape from the teacher to the student, but also judge the learning effect of the student network. As a result, KTNet makes use of a more comprehensive understanding to establish the geometric correspondence between complete and incomplete shapes in a perspective of knowledge transfer, which enables more detailed geometric inference for generating high-quality complete shapes. We conduct comprehensive experiments on several datasets, and the results show that our method outperforms previous methods of unpaired point cloud completion by a large margin. Code is available at https://github.com/a4152684/KT-Net.","[""CV: 3D Computer Vision"", ""CV: Applications""]","[""Zhen Cao"", ""Wenxiao Zhang"", ""Xin Wen"", ""Zhen Dong"", ""Yu-Shen Liu"", ""Xiongwu Xiao"", ""Bisheng Yang""]",https://ojs.aaai.org/index.php/AAAI/article/view/25101/24873,AAAI
How to Cut a Discrete Cake Fairly,"Cake-cutting is a fundamental model of dividing a heterogeneous resource, such as land, broadcast time, and advertisement space. In this study, we consider the problem of dividing indivisible goods fairly under the connectivity constraints of a path. We prove that a connected division of indivisible items satisfying a discrete counterpart of envy-freeness, called envy-freeness up to one good (EF1), always exists for any number of agents n with monotone valuations. Our result settles an open question raised by BilÃ² et al. (2019), who proved that an EF1 connected division always exists for four agents with monotone valuations. Moreover, the proof can be extended to show the following (1) ``secretive"" and (2) ``extra"" versions: (1) for n agents with monotone valuations, the path can be divided into n connected bundles such that an EF1 assignment of the remaining bundles can be made to the other agents for any selection made by the â€œsecretive agentâ€? (2) for n+1 agents with monotone valuations, the path can be divided into n connected bundles such that when any ``extra agentâ€?leaves, an EF1 assignment of the bundles can be made to the remaining agents.","[""GTEP: Fair Division"", ""GTEP: Social Choice / Voting""]","[""Ayumi Igarashi""]",https://ojs.aaai.org/index.php/AAAI/article/view/25705/25477,AAAI
Improving Interpretability of Deep Sequential Knowledge Tracing Models with Question-centric Cognitive Representations,"Knowledge tracing (KT) is a crucial technique to predict studentsâ€?future performance by observing their historical learning processes. Due to the powerful representation ability of deep neural networks, remarkable progress has been made by using deep learning techniques to solve the KT problem. The majority of existing approaches rely on the homogeneous question assumption that questions have equivalent contributions if they share the same set of knowledge components. Unfortunately, this assumption is inaccurate in real-world educational scenarios. Furthermore, it is very challenging to interpret the prediction results from the existing deep learning based KT models. Therefore, in this paper, we present QIKT, a question-centric interpretable KT model to address the above challenges. The proposed QIKT approach explicitly models studentsâ€?knowledge state variations at a ï¬�ne-grained level with question-sensitive cognitive representations that are jointly learned from a question-centric knowledge acquisition module and a question-centric problem solving module. Meanwhile, the QIKT utilizes an item response theory based prediction layer to generate interpretable prediction results. The proposed QIKT model is evaluated on three public real-world educational datasets. The results demonstrate that our approach is superior on the KT prediction task, and it outperforms a wide range of deep learning based KT models in terms of prediction accuracy with better model interpretability. To encourage reproducible results, we have provided all the datasets and code at https://pykt.org/.","[""General""]","[""Jiahao Chen"", ""Zitao Liu"", ""Shuyan Huang"", ""Qiongqiong Liu"", ""Weiqi Luo""]",https://ojs.aaai.org/index.php/AAAI/article/view/26661/26433,AAAI
Semi-Supervised Deep Regression with Uncertainty Consistency and Variational Model Ensembling via Bayesian Neural Networks,"Deep regression is an important problem with numerous applications. These range from computer vision tasks such as age estimation from photographs, to medical tasks such as ejection fraction estimation from echocardiograms for disease tracking.
Semi-supervised approaches for deep regression are notably under-explored compared to classification and segmentation tasks, however.
Unlike classification tasks, which rely on thresholding functions for generating class pseudo-labels, regression tasks use real number target predictions directly as pseudo-labels, making them more sensitive to prediction quality.
In this work, we propose a novel approach to semi-supervised regression, namely Uncertainty-Consistent Variational Model Ensembling (UCVME), which improves training by generating high-quality pseudo-labels and uncertainty estimates for heteroscedastic regression.
Given that aleatoric uncertainty is only dependent on input data by definition and should be equal for the same inputs, we present a novel uncertainty consistency loss for co-trained models.
Our consistency loss significantly improves uncertainty estimates and allows higher quality pseudo-labels to be assigned greater importance under heteroscedastic regression.
Furthermore, we introduce a novel variational model ensembling approach to reduce prediction noise and generate more robust pseudo-labels. We analytically show our method generates higher quality targets for unlabeled data and further improves training.
Experiments show that our method outperforms state-of-the-art alternatives on different tasks and can be competitive with supervised methods that use full labels. Code is available at https://github.com/xmed-lab/UCVME.","[""ML: Semi-Supervised Learning"", ""CV: Learning & Optimization for CV"", ""CV: Medical and Biological Imaging"", ""APP: Healthcare"", ""Medicine & Wellness"", ""ML: Bayesian Learning"", ""ML: Classification and Regression"", ""ML: Deep Neural Network Algorithms"", ""RU: Bayesian Networks""]","[""Weihang Dai"", ""Xiaomeng Li"", ""Kwang-Ting Cheng""]",https://ojs.aaai.org/index.php/AAAI/article/view/25890/25662,AAAI
Personalized Dialogue Generation with Persona-Adaptive Attention,"Persona-based dialogue systems aim to generate consistent responses based on historical context and predefined persona. Unlike conventional dialogue generation, the persona-based dialogue needs to consider both dialogue context and persona, posing a challenge for coherent training. Specifically, this requires a delicate weight balance between context and persona. To achieve that, in this paper, we propose an effective framework with Persona-Adaptive Attention (PAA), which adaptively integrates the weights from the persona and context information via our designed attention. In addition, a dynamic masking mechanism is applied to the PAA to not only drop redundant information in context and persona but also serve as a regularization mechanism to avoid overfitting. Experimental results demonstrate the superiority of the proposed PAA framework compared to the strong baselines in both automatic and human evaluation. Moreover, the proposed PAA approach can perform equivalently well in a low-resource regime compared to models trained in a full-data setting, which achieve a similar result with only 20% to 30% of data compared to the larger models trained in the full-data setting. To fully exploit the effectiveness of our design, we designed several variants for handling the weighted information in different ways, showing the necessity and sufficiency of our weighting and masking designs.","[""SNLP: Conversational AI/Dialogue Systems"", ""SNLP: Applications""]","[""Qiushi Huang"", ""Yu Zhang"", ""Tom Ko"", ""Xubo Liu"", ""Bo Wu"", ""Wenwu Wang"", ""H Tang""]",https://ojs.aaai.org/index.php/AAAI/article/view/26518/26290,AAAI
Model-Based Offline Reinforcement Learning with Local Misspecification,"We present a model-based offline reinforcement learning policy performance lower bound that explicitly captures dynamics model misspecification and distribution mismatch and we propose an empirical algorithm for optimal offline policy selection. Theoretically, we prove a novel safe policy improvement theorem by establishing pessimism approximations to the value function. Our key insight is to jointly consider selecting over dynamics models and policies: as long as a dynamics model can accurately represent the dynamics of the state-action pairs visited by a given policy, it is possible to approximate the value of that particular policy. We analyze our lower bound in the LQR setting and also show competitive performance to previous lower bounds on policy selection across a set of D4RL tasks.","[""ML: Reinforcement Learning Theory"", ""ML: Reinforcement Learning Algorithms""]","[""Kefan Dong"", ""Yannis Flet-Berliac"", ""Allen Nie"", ""Emma Brunskill""]",https://ojs.aaai.org/index.php/AAAI/article/view/25903/25675,AAAI
Occupancy Planes for Single-View RGB-D Human Reconstruction,"Single-view RGB-D human reconstruction with implicit functions is often formulated as per-point classification. Specifically,  a set of 3D locations within the view-frustum of the camera are first projected independently onto the image and a corresponding feature is subsequently extracted for each 3D location. The feature of each 3D location is then used to classify independently whether the corresponding 3D point is inside or outside the observed object. This procedure leads to sub-optimal results because correlations between predictions for neighboring locations are only taken into account implicitly via the extracted features. For more accurate results we propose the occupancy planes (OPlanes) representation, which enables to formulate single-view RGB-D human reconstruction as occupancy prediction on planes which slice through the camera's view frustum. Such a representation provides more flexibility than voxel grids and enables to better leverage correlations than per-point classification. On the challenging S3D data we observe a simple classifier based on the OPlanes representation to yield compelling results, especially in difficult situations with partial occlusions due to other objects and partial visibility, which haven't been addressed by prior work.","[""CV: 3D Computer Vision""]","[""Xiaoming Zhao"", ""Yuan-Ting Hu"", ""Zhongzheng Ren"", ""Alexander G. Schwing""]",https://ojs.aaai.org/index.php/AAAI/article/view/25474/25246,AAAI
Emergent Quantized Communication,"The field of emergent communication aims to understand the characteristics of communication as it emerges from artificial agents solving tasks that require information exchange. Communication with discrete messages is considered a desired characteristic, for scientific and applied reasons. However,  training a multi-agent system with discrete communication is not straightforward, requiring either reinforcement learning algorithms or relaxing the discreteness requirement via a continuous approximation such as the Gumbel-softmax. Both these solutions result in poor performance compared to fully continuous communication. In this work, we propose an alternative approach to achieve discrete communication -- quantization of communicated message. Using message quantization allows us to train the model end-to-end, achieving superior performance in multiple setups. Moreover, quantization is a natural framework that runs the gamut from continuous to discrete communication. Thus,  it sets the ground for a broader view of multi-agent communication in the deep learning era.","[""MAS: Agent Communication"", ""ML: Applications"", ""ML: Deep Neural Architectures"", ""ML: Representation Learning"", ""MAS: Agent-Based Simulation and Emergent Behavior"", ""MAS: Coordination and Collaboration"", ""MAS: Distributed Problem Solving""]","[""Boaz Carmeli"", ""Ron Meir"", ""Yonatan Belinkov""]",https://ojs.aaai.org/index.php/AAAI/article/view/26363/26135,AAAI
A Set of Control Points Conditioned Pedestrian Trajectory Prediction,"Predicting the trajectories of pedestrians in crowded conditions is an important task for applications like autonomous navigation systems. Previous studies have tackled this problem using two strategies. They (1) infer all future steps recursively, or (2) predict the potential destinations of pedestrians at once and interpolate the intermediate steps to arrive there. However, these strategies often suffer from the accumulated errors of the recursive inference, or restrictive assumptions about social relations in the intermediate path. In this paper, we present a graph convolutional network-based trajectory prediction. Firstly, we propose a control point prediction that divides the future path into three sections and infers the intermediate destinations of pedestrians to reduce the accumulated error. To do this, we construct multi-relational weighted graphs to account for their physical and complex social relations. We then introduce a trajectory refinement step based on a spatio-temporal and multi-relational graph. By considering the social interactions between neighbors, better prediction results are achievable. In experiments, the proposed network achieves state-of-the-art performance on various real-world trajectory prediction benchmarks.","[""ROB: Motion and Path Planning"", ""ROB: Behavior Learning & Control"", ""ROB: Multi-Robot Systems"", ""CV: Motion & Tracking""]","[""Inhwan Bae"", ""Hae-Gon Jeon""]",https://ojs.aaai.org/index.php/AAAI/article/view/25759/25531,AAAI
Self-Supervised Logic Induction for Explainable Fuzzy Temporal Commonsense Reasoning,"Understanding temporal commonsense concepts, such as times of occurrence and durations is crucial for event-centric language understanding. Reasoning about such temporal concepts in a complex context requires reasoning over both the stated context and the world knowledge that underlines it. A recent study shows massive pre-trained LM still struggle with such temporal reasoning under complex contexts (e.g., dialog) because they only implicitly encode the relevant contexts and fail to explicitly uncover the underlying logical compositions for complex inference, thus may not be robust enough. In this work, we propose to augment LMs with the temporal logic induction ability, which frames the temporal reasoning by defining three modular components: temporal dependency inducer and temporal concept defuzzifier and logic validator. The former two components disentangle the explicit/implicit dependency between temporal concepts across context (before, after, ...) and the specific meaning of fuzzy temporal concepts, respectively, while the validator combines the intermediate reasoning clues for robust contextual reasoning about the temporal concepts. Extensive experimental results on TIMEDIAL, a challenging dataset for temporal reasoning over dialog, show that our method, Logic Induction Enhanced Contextualized TEmporal Reasoning (LECTER), can yield great improvements over the traditional language model for temporal reasoning.","[""SNLP: Applications"", ""SNLP: Sentence-Level Semantics and Textual Inference""]","[""Bibo Cai"", ""Xiao Ding"", ""Zhouhao Sun"", ""Bing Qin"", ""Ting Liu"", ""Baojun wang"", ""Lifeng Shang""]",https://ojs.aaai.org/index.php/AAAI/article/view/26481/26253,AAAI
Topological Pooling on Graphs,"Graph neural networks (GNNs) have demonstrated a significant success in various graph learning tasks, from graph classification to anomaly detection. There recently has emerged a number of approaches adopting a graph pooling operation within GNNs, with a goal to preserve graph attributive and structural features during the graph representation learning. However, most existing graph pooling operations suffer from the limitations of relying on node-wise neighbor weighting and embedding, which leads to insufficient encoding of rich topological structures and node attributes exhibited by real-world networks. By invoking the machinery of persistent homology and the concept of landmarks, we propose a novel topological pooling layer and witness complex-based topological embedding mechanism that allow us to systematically integrate hidden topological information at both local and global levels. Specifically, we design new learnable local and global topological representations Wit-TopoPool which allow us to simultaneously extract rich discriminative topological information from graphs. Experiments on 11 diverse benchmark datasets against 18 baseline models in conjunction with graph classification tasks indicate that Wit-TopoPool significantly outperforms all competitors across all datasets.","[""ML: Representation Learning"", ""ML: Graph-based Machine Learning""]","[""Yuzhou Chen"", ""Yulia R. Gel""]",https://ojs.aaai.org/index.php/AAAI/article/view/25866/25638,AAAI
A Pair-Approximation Method for Modelling the Dynamics of Multi-Agent Stochastic Games,"Developing a dynamical model for learning in games has attracted much recent interest. In stochastic games, agents need to make decisions in multiple states, and transitions between states, in turn, influence the dynamics of strategies. While previous works typically focus either on 2-agent stochastic games or on normal form games under an infinite-agent setting, we aim at formally modelling the learning dynamics in stochastic games under the infinite-agent setting. With a novel use of pair-approximation method, we develop a formal model for myopic Q-learning in stochastic games with symmetric state transition. We verify the descriptive power of our model (a partial differential equation) across various games through comparisons with agent-based simulation results. Based on our proposed model, we can gain qualitative and quantitative insights into the influence of transition probabilities on the dynamics of strategies. In particular, we illustrate that a careful design of transition probabilities can help players overcome the social dilemmas and promote cooperation, even if agents are myopic learners.","[""GTEP: Game Theory"", ""MAS: Agent-Based Simulation and Emergent Behavior""]","[""Chen Chu"", ""Zheng Yuan"", ""Shuyue Hu"", ""Chunjiang Mu"", ""Zhen Wang""]",https://ojs.aaai.org/index.php/AAAI/article/view/25691/25463,AAAI
HybridCap: Inertia-Aid Monocular Capture of Challenging Human Motions,"Monocular 3D motion capture (mocap) is beneficial to many applications. The use of a single camera, however, often fails to handle occlusions of different body parts and hence it is limited to capture relatively simple movements. We present a light-weight, hybrid mocap technique called HybridCap that augments the camera with only 4 Inertial Measurement Units (IMUs) in a novel learning-and-optimization framework. We first employ a weakly-supervised and hierarchical motion inference module based on cooperative pure residual recurrent blocks that serve as limb, body and root trackers as well as an inverse kinematics solver. Our network effectively narrows the search space of plausible motions via coarse-to-fine pose estimation and manages to tackle challenging movements with high efficiency. We further develop a hybrid optimization scheme that combines inertial feedback and visual cues to improve tracking accuracy. Extensive experiments on various datasets demonstrate HybridCap can robustly handle challenging movements ranging from fitness actions to Latin dance. It also achieves real-time performance up to 60 fps with state-of-the-art accuracy.","[""CV: Biometrics"", ""Face"", ""Gesture & Pose"", ""CV: Computational Photography"", ""Image & Video Synthesis"", ""CV: Motion & Tracking"", ""CV: Multi-modal Vision""]","[""Han Liang"", ""Yannan He"", ""Chengfeng Zhao"", ""Mutian Li"", ""Jingya Wang"", ""Jingyi Yu"", ""Lan Xu""]",https://ojs.aaai.org/index.php/AAAI/article/view/25240/25012,AAAI
Towards Real-Time Segmentation on the Edge,"The research in real-time segmentation mainly focuses on desktop GPUs.
However, autonomous driving and many other applications rely on real-time segmentation on the edge, and current arts are far from the goal.
In addition, recent advances in vision transformers also inspire us to re-design the network architecture for dense prediction task.
In this work, we propose to combine the self attention block with lightweight convolutions to form new building blocks, and employ latency constraints to search an efficient sub-network.
We train an MLP latency model based on generated architecture configurations and their latency measured on mobile devices, so that we can predict the latency of subnets during search phase.
To the best of our knowledge, we are the first to achieve over 74% mIoU on Cityscapes with semi-real-time inference (over 15 FPS) on mobile GPU from an off-the-shelf phone.","[""CV: Segmentation"", ""ML: Auto ML and Hyperparameter Tuning"", ""ML: Learning on the Edge & Model Compression""]","[""Yanyu Li"", ""Changdi Yang"", ""Pu Zhao"", ""Geng Yuan"", ""Wei Niu"", ""Jiexiong Guan"", ""Hao Tang"", ""Minghai Qin"", ""Qing Jin"", ""Bin Ren"", ""Xue Lin"", ""Yanzhi Wang""]",https://ojs.aaai.org/index.php/AAAI/article/view/25232/25004,AAAI
Towards Decision-Friendly AUC: Learning Multi-Classifier with AUCÂµ,"Area Under the ROC Curve (AUC) is a widely used ranking metric in imbalanced learning due to its insensitivity to label distributions. As a well-known multiclass extension of AUC, Multiclass AUC (MAUC, a.k.a. M-metric) measures the average AUC of multiple binary classifiers. In this paper, we argue that simply optimizing MAUC is far from enough for imbalanced multi-classification. More precisely, MAUC only focuses on learning scoring functions via ranking optimization, while leaving the decision process unconsidered. Therefore, scoring functions being able to make good decisions might suffer from low performance in terms of MAUC. To overcome this issue, we turn to explore AUCÂµ, another multiclass variant of AUC, which further takes the decision process into consideration. Motivated by this fact, we propose a surrogate risk optimization framework to improve model performance from the perspective of AUCÂµ. Practically, we propose a two-stage training framework for multi-classification, where at the first stage a scoring function is learned maximizing AUCÂµ, and at the second stage we seek for a decision function to improve the F1-metric via our proposed soft F1. Theoretically, we first provide sufficient conditions that optimizing the surrogate losses could lead to the Bayes optimal scoring function. Afterward, we show that the proposed surrogate risk enjoys a generalization bound in order of O(1/âˆšN). Experimental results on four benchmark datasets demonstrate the effectiveness of our proposed method in both AUCÂµ and F1-metric.","[""ML: Multi-Class/Multi-Label Learning & Extreme Classification"", ""ML: Classification and Regression""]","[""Peifeng Gao"", ""Qianqian Xu"", ""Peisong Wen"", ""Huiyang Shao"", ""Yuan He"", ""Qingming Huang""]",https://ojs.aaai.org/index.php/AAAI/article/view/25926/25698,AAAI
Directed Acyclic Graph Structure Learning from Dynamic Graphs,"Estimating the structure of directed acyclic graphs (DAGs) of features (variables) plays a vital role in revealing the latent data generation process and providing causal insights in various applications. Although there have been many studies on structure learning with various types of data, the structure learning on the dynamic graph has not been explored yet, and thus we study the learning problem of node feature generation mechanism on such ubiquitous dynamic graph data. In a dynamic graph, we propose to simultaneously estimate contemporaneous relationships and time-lagged interaction relationships between the node features. These two kinds of relationships form a DAG, which could effectively characterize the feature generation process in a concise way. To learn such a DAG, we cast the learning problem as a continuous score-based optimization problem, which consists of a differentiable score function to measure the validity of the learned DAGs and a smooth acyclicity constraint to ensure the acyclicity of the learned DAGs. These two components are translated into an unconstraint augmented Lagrangian objective which could be minimized by mature continuous optimization techniques. The resulting algorithm, named GraphNOTEARS, outperforms baselines on simulated data across a wide range of settings that may encounter in real-world applications. We also apply the proposed approach on two dynamic graphs constructed from the real-world Yelp dataset, demonstrating our method could learn the connections between node features, which conforms with the domain knowledge.","[""ML: Graph-based Machine Learning"", ""DMKM: Graph Mining"", ""Social Network Analysis & Community Mining"", ""ML: Causal Learning""]","[""Shaohua Fan"", ""Shuyang Zhang"", ""Xiao Wang"", ""Chuan Shi""]",https://ojs.aaai.org/index.php/AAAI/article/view/25913/25685,AAAI
Fast and Accurate Binary Neural Networks Based on Depth-Width Reshaping,"Network binarization (i.e., binary neural networks, BNNs) can efficiently compress deep neural networks and accelerate model inference but cause severe accuracy degradation. Existing BNNs are mainly implemented based on the commonly used full-precision network backbones, and then the accuracy is improved with various techniques. However, there is a question of whether the full-precision network backbone is well adapted to BNNs. We start from the factors of the performance degradation of BNNs and analyze the problems of directly using full-precision network backbones for BNNs: for a given computational budget, the backbone of a BNN may need to be shallower and wider compared to the backbone of a full-precision network. With this in mind, Depth-Width Reshaping (DWR) is proposed to reshape the depth and width of existing full-precision network backbones and further optimize them by incorporating pruning techniques to better fit the BNNs. Extensive experiments demonstrate the analytical result and the effectiveness of the proposed method. Compared with the original backbones, the DWR backbones constructed by the proposed method result in close to O(âˆšs) decrease in activations, while achieving an absolute accuracy increase by up to 1.7% with comparable computational cost. Besides, by using the DWR backbones, existing methods can achieve new state-of-the-art (SOTA) accuracy (e.g., 67.2% on ImageNet with ResNet-18 as the original backbone). We hope this work provides a novel insight into the backbone design of BNNs. The code is available at https://github.com/pingxue-hfut/DWR.","[""ML: Learning on the Edge & Model Compression""]","[""Ping Xue"", ""Yang Lu"", ""Jingfei Chang"", ""Xing Wei"", ""Zhen Wei""]",https://ojs.aaai.org/index.php/AAAI/article/view/26268/26040,AAAI
Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation,"Self-supervised monocular depth estimation has been widely studied recently. Most of the work has focused on improving performance on benchmark datasets, such as KITTI, but has offered a few experiments on generalization performance. In this paper, we investigate the backbone networks (e.g., CNNs, Transformers, and CNN-Transformer hybrid models) toward the generalization of monocular depth estimation. We first evaluate state-of-the-art models on diverse public datasets, which have never been seen during the network training. Next, we investigate the effects of texture-biased and shape-biased representations using the various texture-shifted datasets that we generated. We observe that Transformers exhibit a strong shape bias and CNNs do a strong texture-bias. We also find that shape-biased models show better generalization performance for monocular depth estimation compared to texture-biased models. Based on these observations, we newly design a CNN-Transformer hybrid network with a multi-level adaptive feature fusion module, called MonoFormer. The design intuition behind MonoFormer is to increase shape bias by employing Transformers while compensating for the weak locality bias of Transformers by adaptively fusing multi-level representations. Extensive experiments show that the proposed method achieves state-of-the-art performance with various public datasets. Our method also shows the best generalization ability among the competitive methods.","[""CV: 3D Computer Vision"", ""CV: Adversarial Attacks & Robustness"", ""CV: Applications"", ""CV: Vision for Robotics & Autonomous Driving""]","[""Jinwoo Bae"", ""Sungho Moon"", ""Sunghoon Im""]",https://ojs.aaai.org/index.php/AAAI/article/view/25090/24862,AAAI
BEVStereo: Enhancing Depth Estimation in Multi-View 3D Object Detection with Temporal Stereo,"Restricted by the ability of depth perception, all Multi-view 3D object detection methods fall into the bottleneck of depth accuracy. By constructing temporal stereo, depth estimation is quite reliable in indoor scenarios. However, there are two difficulties in directly integrating temporal stereo into outdoor multi-view 3D object detectors: 1) The construction of temporal stereos for all views results in high computing costs. 2) Unable to adapt to challenging outdoor scenarios. In this study, we propose an effective method for creating temporal stereo by dynamically determining the center and range of the temporal stereo. The most confident center is found using the EM algorithm. Numerous experiments on nuScenes have shown the BEVStereo's ability to deal with complex outdoor scenarios that other stereo-based methods are unable to handle.  For the first time, a stereo-based approach shows superiority in scenarios like a static ego vehicle and moving objects. BEVStereo achieves the new state-of-the-art in the camera-only track of nuScenes dataset while maintaining memory efficiency.  Codes have been released.","[""CV: 3D Computer Vision"", ""CV: Vision for Robotics & Autonomous Driving""]","[""Yinhao Li"", ""Han Bao"", ""Zheng Ge"", ""Jinrong Yang"", ""Jianjian Sun"", ""Zeming Li""]",https://ojs.aaai.org/index.php/AAAI/article/view/25234/25006,AAAI
Kajibuntan: A House Chore Division App,"Couples often encounter the challenge of sharing house chores.  This raises the fundamental question of how to divide chores. In this paper, we present a new application for a fair division of household chores. Our platform, called Kajibuntan, allows couples to specify the set of chores to be shared, their preferences over them, and the current allocation. Our tool visualizes the current allocation and makes proposals according to their preferences based on the theory of fair division. The goal of our tool is to provide a systematic and transparent system to divide household chores and help creating harmony in the home.","[""Fair Division"", ""Chores"", ""Envy-freeness""]","[""Ayumi Igarashi"", ""Tomohiko Yokoyama""]",https://ojs.aaai.org/index.php/AAAI/article/view/27075/26847,AAAI
Phase-Informed Bayesian Ensemble Models Improve Performance of COVID-19 Forecasts,"Despite hundreds of methods published in the literature, forecasting epidemic dynamics remains challenging yet important. The challenges stem from multiple sources, including: the need for timely data, co-evolution of epidemic dynamics with behavioral and immunological adaptations, and the evolution of new pathogen strains. The ongoing COVID-19 pandemic highlighted these challenges; in an important article, Reich et al. did a comprehensive analysis highlighting many of these challenges.

In this paper, we take another step in critically evaluating existing epidemic forecasting methods. Our methods are based on a simple yet crucial observation - epidemic dynamics go through a number of phases (waves). Armed with this understanding, we propose a modification to our deployed Bayesian ensembling case time series forecasting framework. We show that ensembling methods employing the phase information and using different weighting schemes for each phase can produce improved forecasts. We evaluate our proposed method with both the currently deployed model and the COVID-19 forecasthub models. The overall performance of the proposed model is consistent across the pandemic but more importantly, it is ranked third and first during two critical rapid growth phases in cases, regimes where the performance of most models from the CDC forecasting hub dropped significantly.","[""Disease Forecasting"", ""Bayesian Model Averaging"", ""Ensemble Methods"", ""COVID-19 Forecasting"", ""Ablation Analysis""]","[""Aniruddha Adiga"", ""Gursharn Kaur"", ""Lijing Wang"", ""Benjamin Hurt"", ""Przemyslaw Porebski"", ""Srinivasan Venkatramanan"", ""Bryan Lewis"", ""Madhav V. Marathe""]",https://ojs.aaai.org/index.php/AAAI/article/view/26855/26627,AAAI
SegFormer: A Topic Segmentation Model with Controllable Range of Attention,"Topic segmentation aims to reveal the latent structure of a document and divide it into multiple parts. However, current neural solutions are limited in the context modeling of sentences and feature representation of candidate boundaries. This causes the model to suffer from inefficient sentence context encoding and noise information interference. In this paper, we design a new text segmentation model SegFormer with unidirectional attention blocks to better model sentence representations. To alleviate the problem of noise information interference, SegFormer uses a novel additional context aggregator and a topic classification loss to guide the model to aggregate the information within the appropriate range.  In addition, SegFormer applies an iterative prediction algorithm to search for optimal boundaries progressively. We evaluate SegFormer's generalization ability, multilingual ability, and application ability on multiple challenging real-world datasets. Experiments show that our model significantly improves the performance by 7.5% on the benchmark WIKI-SECTION compared to several strong baselines. The application of SegFormer to a real-world dataset to separate normal and advertisement segments in product marketing essays also achieves superior performance in the evaluation with other cutting-edge models.","[""SNLP: Applications"", ""SNLP: Information Extraction"", ""SNLP: Language Models"", ""SNLP: Machine Translation & Multilinguality"", ""SNLP: Sentence-Level Semantics and Textual Inference"", ""SNLP: Summarization"", ""SNLP: Text Classification"", ""SNLP: Text Mining""]","[""Haitao Bai"", ""Pinghui Wang"", ""Ruofei Zhang"", ""Zhou Su""]",https://ojs.aaai.org/index.php/AAAI/article/view/26477/26249,AAAI
SkateboardAI: The Coolest Video Action Recognition for Skateboarding (Student Abstract),"Impressed by the coolest skateboarding sports program from 2021 Tokyo Olympic Games, we are the first to curate the original real-world video datasets ""SkateboardAI"" in the wild, even self-design and implement diverse uni-modal and multi-modal video action recognition approaches to recognize different tricks accurately. For uni-modal methods, we separately apply (1)CNN and LSTM; (2)CNN and BiLSTM; (3)CNN and BiLSTM with effective attention mechanisms; (4)Transformer-based action recognition pipeline. Transferred to the multi-modal conditions, we investigated the two-stream Inflated-3D architecture on ""SkateboardAI"" datasets to compare its performance with uni-modal cases. In sum, our objective is developing an excellent AI sport referee for the coolest skateboarding competitions.","[""Action Recognition"", ""Video Classification"", ""Skateboarding"", ""Transformer"", ""Multi-modal Learning""]","[""Hanxiao Chen""]",https://ojs.aaai.org/index.php/AAAI/article/view/26952/26724,AAAI
DASH: A Distributed and Parallelizable Algorithm for Size-Constrained Submodular Maximization,"MapReduce (MR) algorithms for maximizing monotone, submodular functions subject to a cardinality constraint (SMCC) are currently restricted to the use of the linear-adaptive (non-parallelizable) algorithm GREEDY. Low-adaptive algorithms do not satisfy the requirements of these distributed MR frameworks, thereby limiting their performance. We study the SMCC problem in a distributed setting and propose the first MR algorithms with sublinear adaptive complexity. Our algorithms, R-DASH, T-DASH and G-DASH provide 0.316 - Îµ, 3/8 - Îµ , and (1 - 1/e - Îµ)   approximation ratios, respectively, with nearly optimal adaptive complexity and nearly linear time complexity. Additionally, we provide a framework to increase, under some mild assumptions, the maximum permissible cardinality constraint from  O( n / â„“^2) of prior MR algorithms to O( n / â„?), where n is the data size and â„?is the number of machines; under a stronger condition on the objective function, we increase the maximum constraint value to n. Finally, we provide empirical evidence to demonstrate that our sublinear-adaptive, distributed algorithms provide orders of magnitude faster runtime compared to current state-of-the-art distributed algorithms.","[""CSO: Distributed CSP/Optimization"", ""CSO: Constraint Optimization"", ""CSO: Constraint Programming"", ""CSO: Constraint Satisfaction"", ""CSO: Other Foundations of Constraint Satisfaction & Optimization""]","[""Tonmoy Dey"", ""Yixin Chen"", ""Alan Kuhnle""]",https://ojs.aaai.org/index.php/AAAI/article/view/25508/25280,AAAI
Few-Shot Object Detection via Variational Feature Aggregation,"As few-shot object detectors are often trained with abundant base samples and fine-tuned on few-shot novel examples, the learned models are usually biased to base classes and sensitive to the variance of novel examples. To address this issue, we propose a meta-learning framework with two novel feature aggregation schemes. More precisely, we first present a Class-Agnostic Aggregation (CAA) method, where the query and support features can be aggregated regardless of their categories. The interactions between different classes encourage class-agnostic representations and reduce confusion between base and novel classes.
Based on the CAA, we then propose a Variational Feature Aggregation (VFA) method, which encodes support examples into class-level support features for robust feature aggregation. We use a variational autoencoder to estimate class distributions and sample variational features from distributions that are more robust to the variance of support examples. Besides, we decouple classification and regression tasks so that VFA is performed on the classification branch without affecting object localization. Extensive experiments on PASCAL VOC and COCO demonstrate that our method significantly outperforms a strong baseline (up to 16%) and previous state-of-the-art methods (4% in average).","[""CV: Object Detection & Categorization""]","[""Jiaming Han"", ""Yuqiang Ren"", ""Jian Ding"", ""Ke Yan"", ""Gui-Song Xia""]",https://ojs.aaai.org/index.php/AAAI/article/view/25153/24925,AAAI
Fair Short Paths in Vertex-Colored Graphs,"The computation of short paths in graphs with arc lengths is a pillar of graph algorithmics and network science. In a more diverse world, however, not every short path is equally valuable. For the setting where each vertex is assigned to a group (color), we provide a framework to model multiple natural fairness aspects. We seek to find short paths in which the number of occurrences of each color is within some given lower and upper bounds. Among other results, we prove the introduced problems to be computationally intractable (NP-hard and parameterized hard with respect to the number of colors) even in very restricted settings (such as each color should appear with exactly the same frequency), while also presenting an encouraging algorithmic result (""fixed-parameter tractability"") related to the length of the sought solution path for the general problem.","[""SO: Mixed Discrete/Continuous Search"", ""GTEP: Coordination and Collaboration""]","[""Matthias Bentert"", ""Leon Kellerhals"", ""Rolf Niedermeier""]",https://ojs.aaai.org/index.php/AAAI/article/view/26455/26227,AAAI
NHITS: Neural Hierarchical Interpolation for Time Series Forecasting,"Recent progress in neural forecasting accelerated improvements in the performance of large-scale forecasting systems. Yet, long-horizon forecasting remains a very difficult task. Two common challenges afflicting the task are the volatility of the predictions and their computational complexity. We introduce NHITS, a model which addresses both challenges by incorporating novel hierarchical interpolation and multi-rate data sampling techniques. These techniques enable the proposed method to assemble its predictions sequentially, emphasizing components with different frequencies and scales while decomposing the input signal and synthesizing the forecast. We prove that the hierarchical interpolation technique can efficiently approximate arbitrarily long horizons in the presence of smoothness. Additionally, we conduct extensive large-scale dataset experiments from the long-horizon forecasting literature, demonstrating the advantages of our method over the state-of-the-art methods, where NHITS provides an average accuracy improvement of almost 20% over the latest Transformer architectures while reducing the computation time by an order of magnitude (50 times). Our code is available at https://github.com/Nixtla/neuralforecast.","[""ML: Time-Series/Data Streams"", ""ML: Deep Neural Architectures""]","[""Cristian Challu"", ""Kin G. Olivares"", ""Boris N. Oreshkin"", ""Federico Garza Ramirez"", ""Max Mergenthaler Canseco"", ""Artur Dubrawski""]",https://ojs.aaai.org/index.php/AAAI/article/view/25854/25626,AAAI
CP-Rec: Contextual Prompting for Conversational Recommender Systems,"The conversational recommender system (CRS) aims to provide high-quality recommendations through interactive dialogues. However, previous CRS models have no effective mechanisms for task planning and topic elaboration, and thus they hardly maintain coherence in multi-task recommendation dialogues. Inspired by recent advances in prompt-based learning, we propose a novel contextual prompting framework for dialogue management, which optimizes prompts based on context, topics, and user profiles. Specifically, we develop a topic controller to sequentially plan the subtasks, and a prompt search module to construct context-aware prompts. We further adopt external knowledge to enrich user profiles and make knowledge-aware recommendations. Incorporating these techniques, we propose a conversational recommender system with contextual prompting, namely CP-Rec. Experimental results demonstrate that it achieves state-of-the-art recommendation accuracy and generates more coherent and informative conversations.","[""SNLP: Conversational AI/Dialogue Systems""]","[""Keyu Chen"", ""Shiliang Sun""]",https://ojs.aaai.org/index.php/AAAI/article/view/26487/26259,AAAI
TransPath: Learning Heuristics for Grid-Based Pathfinding via Transformers,"Heuristic search algorithms, e.g. A*, are the commonly used tools for pathfinding on grids, i.e. graphs of regular structure that are widely employed to represent environments in robotics, video games, etc. Instance-independent heuristics for grid graphs, e.g. Manhattan distance, do not take the obstacles into account, and thus the search led by such heuristics performs poorly in obstacle-rich environments. To this end, we suggest learning the instance-dependent heuristic proxies that are supposed to notably increase the efficiency of the search. The first heuristic proxy we suggest to learn is the correction factor, i.e. the ratio between the instance-independent cost-to-go estimate and the perfect one (computed offline at the training phase). Unlike learning the absolute values of the cost-to-go heuristic function, which was known before, learning the correction factor utilizes the knowledge of the instance-independent heuristic. The second heuristic proxy is the path probability, which indicates how likely the grid cell is lying on the shortest path. This heuristic can be employed in the Focal Search framework as the secondary heuristic, allowing us to preserve the guarantees on the bounded sub-optimality of the solution. We learn both suggested heuristics in a supervised fashion with the state-of-the-art neural networks containing attention blocks (transformers). We conduct a thorough empirical evaluation on a comprehensive dataset of planning tasks, showing that the suggested techniques i) reduce the computational effort of the A* up to a factor of 4x while producing the solutions, whose costs exceed those of the optimal solutions by less than 0.3% on average; ii) outperform the competitors, which include the conventional techniques from the heuristic search, i.e. weighted A*, as well as the state-of-the-art learnable planners.

The project web-page is: https://airi-institute.github.io/TransPath/.","[""SO: Heuristic Search"", ""ML: Deep Generative Models & Autoencoders"", ""PRS: Planning/Scheduling and Learning""]","[""Daniil Kirilenko"", ""Anton Andreychuk"", ""Aleksandr Panov"", ""Konstantin Yakovlev""]",https://ojs.aaai.org/index.php/AAAI/article/view/26465/26237,AAAI
Meta-Learning for Simple Regret Minimization,"We develop a meta-learning framework for simple regret minimization in bandits. In this framework, a learning agent interacts with a sequence of bandit tasks, which are sampled i.i.d. from an unknown prior distribution, and learns its meta-parameters to perform better on future tasks. We propose the first Bayesian and frequentist meta-learning algorithms for this setting. The Bayesian algorithm has access to a prior distribution over the meta-parameters and its meta simple regret over m bandit tasks with horizon n is mere O(m / âˆšn). On the other hand, the meta simple regret of the frequentist algorithm is O(nâˆšm + m/ âˆšn). While its regret is worse, the frequentist algorithm is more general because it does not need a prior distribution over the meta-parameters. It can also be analyzed in more settings. We instantiate our algorithms for several classes of bandit problems. Our algorithms are general and we complement our theory by evaluating them empirically in several environments.","[""ML: Online Learning & Bandits"", ""ML: Meta Learning""]","[""Javad Azizi"", ""Branislav Kveton"", ""Mohammad Ghavamzadeh"", ""Sumeet Katariya""]",https://ojs.aaai.org/index.php/AAAI/article/view/25823/25595,AAAI
Towards Hybrid Automation by Bootstrapping Conversational Interfaces for IT Operation Tasks,"Process automation has evolved from end-to-end automation of repetitive process branches to hybrid automation where bots perform some activities and humans serve other activities. In the context of knowledge-intensive processes such as IT operations, implementing hybrid automation is a natural choice where robots can perform certain mundane functions, with humans taking over the decision of when and which IT systems need to act. Recently, ChatOps, which refers to conversation-driven collaboration for IT operations, has rapidly accelerated efficiency by providing a cross-organization and cross-domain platform to resolve and manage issues as soon as possible. Hence, providing a natural language interface to bots is a logical progression to enable collaboration between humans and bots. This work presents a no-code approach to provide a conversational interface that enables human workers to collaborate with bots executing automation scripts. The bots identify the intent of users' requests and automatically orchestrate one or more relevant automation tasks to serve the request. We further detail our process of mining the conversations between humans and bots to monitor performance and identify the scope for improvement in service quality.","[""IT Process Automation"", ""Bootstrapping Conversational Interfaces"", ""Hybrid Automation"", ""Human-automation Collaboration"", ""Automation Monitoring""]","[""Jayachandu Bandlamudi"", ""Kushal Mukherjee"", ""Prerna Agarwal"", ""Sampath Dechu"", ""Siyu Huo"", ""Vatche Isahagian"", ""Vinod Muthusamy"", ""Naveen Purushothaman"", ""Renuka Sindhgatta""]",https://ojs.aaai.org/index.php/AAAI/article/view/26856/26628,AAAI
STL-Based Synthesis of Feedback Controllers Using Reinforcement Learning,"Deep Reinforcement Learning (DRL) has the potential to be used for synthesizing feedback controllers (agents) for various complex systems with unknown dynamics. These systems are expected to satisfy diverse safety and liveness properties best captured using temporal logic. In RL, the reward function plays a crucial role in specifying the desired behaviour of these agents. However, the problem of designing the reward function for an RL agent to satisfy complex temporal logic specifications has received limited attention in the literature. To address this, we provide a systematic way of generating rewards in real-time by using the quantitative semantics of Signal Temporal Logic (STL), a widely used temporal logic to specify the behaviour of cyber-physical systems. We propose a new quantitative semantics for STL having several desirable properties, making it suitable for reward generation. We evaluate our STL-based reinforcement learning mechanism on several complex continuous control benchmarks and compare our STL semantics with those available in the literature in terms of their efficacy in synthesizing the controller agent. Experimental results establish our new semantics to be the most suitable for synthesizing feedback controllers for complex continuous dynamical systems through reinforcement learning.","[""General""]","[""Nikhil Kumar Singh"", ""Indranil Saha""]",https://ojs.aaai.org/index.php/AAAI/article/view/26764/26536,AAAI
From Coarse to Fine: Hierarchical Pixel Integration for Lightweight Image Super-resolution,"Image super-resolution (SR) serves as a fundamental tool for the processing and transmission of multimedia data. Recently, Transformer-based models have achieved competitive performances in image SR. They divide images into fixed-size patches and apply self-attention on these patches to model long-range dependencies among pixels. However, this architecture design is originated for high-level vision tasks, which lacks design guideline from SR knowledge. In this paper, we aim to design a new attention block whose insights are from the interpretation of Local Attribution Map (LAM) for SR networks.  Specifically, LAM presents a hierarchical importance map where the most important pixels are located in a fine area of a patch and some less important pixels are spread in a coarse area of the whole image. To access pixels in the coarse area, instead of using a very large patch size, we propose a lightweight Global Pixel Access (GPA) module that applies cross-attention with the most similar patch in an image. In the fine area, we use an Intra-Patch Self-Attention (IPSA) module to model long-range pixel dependencies in a local patch, and then a spatial convolution is applied to process the finest details. In addition, a Cascaded Patch Division (CPD) strategy is proposed to enhance perceptual quality of recovered images. Extensive experiments suggest that our method outperforms state-of-the-art lightweight SR methods by a large margin. Code is available at https://github.com/passerer/HPINet.","[""CV: Low Level & Physics-Based Vision"", ""CV: Computational Photography"", ""Image & Video Synthesis""]","[""Jie Liu"", ""Chao Chen"", ""Jie Tang"", ""Gangshan Wu""]",https://ojs.aaai.org/index.php/AAAI/article/view/25254/25026,AAAI
RankDNN: Learning to Rank for Few-Shot Learning,"This paper introduces a new few-shot learning pipeline that
casts relevance ranking for image retrieval as binary ranking
relation classification. In comparison to image classification,
ranking relation classification is sample efficient and
domain agnostic. Besides, it provides a new perspective on
few-shot learning and is complementary to state-of-the-art
methods. The core component of our deep neural network is
a simple MLP, which takes as input an image triplet encoded
as the difference between two vector-Kronecker products,
and outputs a binary relevance ranking order. The proposed
RankMLP can be built on top of any state-of-the-art feature
extractors, and our entire deep neural network is called
the ranking deep neural network, or RankDNN. Meanwhile,
RankDNN can be flexibly fused with other post-processing
methods. During the meta test, RankDNN ranks support images
according to their similarity with the query samples,
and each query sample is assigned the class label of its
nearest neighbor. Experiments demonstrate that RankDNN
can effectively improve the performance of its baselines
based on a variety of backbones and it outperforms previous
state-of-the-art algorithms on multiple few-shot learning
benchmarks, including miniImageNet, tieredImageNet,
Caltech-UCSD Birds, and CIFAR-FS. Furthermore, experiments
on the cross-domain challenge demonstrate the superior
transferability of RankDNN.The code is available at:
https://github.com/guoqianyu-alberta/RankDNN.","[""CV: Other Foundations of Computer Vision"", ""ML: Learning Preferences or Rankings"", ""ML: Meta Learning"", ""ML: Transfer"", ""Domain Adaptation"", ""Multi-Task Learning""]","[""Qianyu Guo"", ""Gong Haotong"", ""Xujun Wei"", ""Yanwei Fu"", ""Yizhou Yu"", ""Wenqiang Zhang"", ""Weifeng Ge""]",https://ojs.aaai.org/index.php/AAAI/article/view/25150/24922,AAAI
Privacy Attacks on Schedule-Driven Data,"Schedules define how resources process jobs in diverse domains, reaching from healthcare to transportation, and, therefore, denote a valuable starting point for analysis of the underlying system. However, publishing a schedule may disclose private information on the considered jobs. In this paper, we provide a first threat model for published schedules, thereby defining a completely new class of data privacy problems. We then propose distance-based measures to assess the privacy loss incurred by a published schedule, and show their theoretical properties for an uninformed adversary, which can be used as a benchmark for informed attacks. We show how an informed attack on a published schedule can be phrased as an inverse scheduling problem. We instantiate this idea by formulating the inverse of a well-studied single-machine scheduling problem, namely minimizing the total weighted completion times. An empirical evaluation for synthetic scheduling problems shows the effectiveness of informed privacy attacks and compares the results to theoretical bounds on uninformed attacks.","[""PRS: Scheduling"", ""PRS: Applications"", ""PRS: Planning/Scheduling and Learning""]","[""Stephan A. Fahrenkrog-Petersen"", ""Arik Senderovich"", ""Alexandra Tichauer"", ""Ali Kaan Tutak"", ""J. Christopher Beck"", ""Matthias Weidlich""]",https://ojs.aaai.org/index.php/AAAI/article/view/26412/26184,AAAI
Generalizing Downsampling from Regular Data to Graphs,"Downsampling produces coarsened, multi-resolution representations of data and it is used, for example, to produce lossy compression and visualization of large images, reduce computational costs, and boost deep neural representation learning.
Unfortunately, due to their lack of a regular structure, there is still no consensus on how downsampling should apply to graphs and linked data. Indeed reductions in graph data are still needed for the goals described above, but reduction mechanisms do not have the same focus on preserving topological structures and properties, while allowing for resolution-tuning, as is the case in regular data downsampling.
In this paper, we take a step in this direction, introducing a unifying interpretation of downsampling in regular and graph data. In particular, we define a graph coarsening mechanism which is a graph-structured counterpart of controllable equispaced coarsening mechanisms in regular data. We prove theoretical guarantees for distortion bounds on path lengths, as well as the ability to preserve key topological properties in the coarsened graphs. We leverage these concepts to define a graph pooling mechanism that we empirically assess in graph classification tasks, providing a greedy algorithm that allows efficient parallel implementation on GPUs, and showing that it compares favorably against pooling methods in literature.","[""ML: Graph-based Machine Learning"", ""DMKM: Graph Mining"", ""Social Network Analysis & Community Mining""]","[""Davide Bacciu"", ""Alessio Conte"", ""Francesco Landolfi""]",https://ojs.aaai.org/index.php/AAAI/article/view/25824/25596,AAAI
NLIP: Noise-Robust Language-Image Pre-training,"Large-scale cross-modal pre-training paradigms have recently shown ubiquitous success on a wide range of downstream tasks, e.g., zero-shot classification, retrieval and image captioning. However, their successes highly rely on the scale and quality of web-crawled data that naturally contain much incomplete and noisy information (e.g., wrong or irrelevant contents). Existing works either design manual rules to clean data or generate pseudo-targets as auxiliary signals for reducing noise impact, which do not explicitly tackle both the incorrect and incomplete challenges at the same time. In this paper, to automatically mitigate the impact of noise by solely mining over existing data, we propose a principled Noise-robust Language-Image Pre-training framework (NLIP) to stabilize pre-training via two schemes: noise-harmonization and noise-completion. First, in noise-harmonization scheme, NLIP estimates the noise probability of each pair according to the memorization effect of cross-modal transformers, then adopts noise-adaptive regularization to harmonize the cross-modal alignments with varying degrees. Second, in noise-completion scheme, to enrich the missing object information of text, NLIP injects a concept-conditioned cross-modal decoder to obtain semantic-consistent synthetic captions to complete noisy ones, which uses the retrieved visual concepts (i.e., objectsâ€?names) for the corresponding image to guide captioning generation. By collaboratively optimizing noise-harmonization and noise-completion schemes, our NLIP can alleviate the common noise effects during image-text pre-training in a more efficient way. Extensive experiments show the significant performance improvements of our NLIP using only 26M data over existing pre-trained models (e.g., CLIP, FILIP and BLIP) on 12 zero-shot classification datasets (e.g., +8.6% over CLIP on average accuracy), MSCOCO image captioning (e.g., +1.9 over BLIP trained with 129M data on CIDEr) and zero-shot image-text retrieval tasks.","[""CV: Language and Vision"", ""CV: Representation Learning for Vision""]","[""Runhui Huang"", ""Yanxin Long"", ""Jianhua Han"", ""Hang Xu"", ""Xiwen Liang"", ""Chunjing Xu"", ""Xiaodan Liang""]",https://ojs.aaai.org/index.php/AAAI/article/view/25172/24944,AAAI
Frequency Domain Disentanglement for Arbitrary Neural Style Transfer,"Arbitrary neural style transfer has been a popular research topic due to its rich application scenarios. Effective disentanglement of content and style is the critical factor for synthesizing an image with arbitrary style. The existing methods focus on disentangling feature representations of content and style in the spatial domain where the content and style components are innately entangled and difficult to be disentangled clearly. Therefore, these methods always suffer from low-quality results because of the sub-optimal disentanglement. To address such a challenge, this paper proposes the frequency mixer (FreMixer) module that disentangles and re-entangles the frequency spectrum of content and style components in the frequency domain. Since content and style components have different frequency-domain characteristics (frequency bands and frequency patterns), the FreMixer could well disentangle these two components. Based on the FreMixer module, we design a novel Frequency Domain Disentanglement (FDD) framework for arbitrary neural style transfer. Qualitative and quantitative experiments verify that the proposed method can render better stylized results compared to the state-of-the-art methods.","[""CV: Low Level & Physics-Based Vision"", ""CV: Applications""]","[""Dongyang Li"", ""Hao Luo"", ""Pichao Wang"", ""Zhibin Wang"", ""Shang Liu"", ""Fan Wang""]",https://ojs.aaai.org/index.php/AAAI/article/view/25212/24984,AAAI
Let Graph Be the Go Board: Gradient-Free Node Injection Attack for Graph Neural Networks via Reinforcement Learning,"Graph Neural Networks (GNNs) have drawn significant attentions over the years and been broadly applied to essential applications requiring solid robustness or vigorous security standards, such as product recommendation and user behavior modeling. Under these scenarios, exploiting GNN's vulnerabilities and further downgrading its performance become extremely incentive for adversaries. Previous attackers mainly focus on structural perturbations or node injections to the existing graphs, guided by gradients from the surrogate models. Although they deliver promising results, several limitations still exist. For the structural perturbation attack, to launch a proposed attack, adversaries need to manipulate the existing graph topology, which is impractical in most circumstances. Whereas for the node injection attack, though being more practical, current approaches require training surrogate models to simulate a white-box setting, which results in significant performance downgrade when the surrogate architecture diverges from the actual victim model. To bridge these gaps, in this paper, we study the problem of black-box node injection attack, without training a potentially misleading surrogate model. Specifically, we model the node injection attack as a Markov decision process and propose Gradient-free Graph Advantage Actor Critic, namely G2A2C, a reinforcement learning framework in the fashion of advantage actor critic. By directly querying the victim model, G2A2C learns to inject highly malicious nodes with extremely limited attacking budgets, while maintaining a similar node feature distribution. Through our comprehensive experiments over eight acknowledged benchmark datasets with different characteristics, we demonstrate the superior performance of our proposed G2A2C over the existing state-of-the-art attackers. Source code is publicly available at: https://github.com/jumxglhf/G2A2C.","[""DMKM: Graph Mining"", ""Social Network Analysis & Community Mining""]","[""Mingxuan Ju"", ""Yujie Fan"", ""Chuxu Zhang"", ""Yanfang Ye""]",https://ojs.aaai.org/index.php/AAAI/article/view/25558/25330,AAAI
Where Will Players Move Next? Dynamic Graphs and Hierarchical Fusion for Movement Forecasting in Badminton,"Sports analytics has captured increasing attention since analysis of the various data enables insights for training strategies, player evaluation, etc. In this paper, we focus on predicting what types of returning strokes will be made, and where players will move to based on previous strokes. As this problem has not been addressed to date, movement forecasting can be tackled through sequence-based and graph-based models by formulating as a sequence prediction task. However, existing sequence-based models neglect the effects of interactions between players, and graph-based models still suffer from multifaceted perspectives on the next movement. Moreover, there is no existing work on representing strategic relations among players' shot types and movements. To address these challenges, we first introduce the procedure of the Player Movements (PM) graph to exploit the structural movements of players with strategic relations. Based on the PM graph, we propose a novel Dynamic Graphs and Hierarchical Fusion for Movement Forecasting model (DyMF) with interaction style extractors to capture the mutual interactions of players themselves and between both players within a rally, and dynamic players' tactics across time. In addition, hierarchical fusion modules are designed to incorporate the style influence of both players and rally interactions. Extensive experiments show that our model empirically outperforms both sequence- and graph-based methods and demonstrate the practical usage of movement forecasting. Code is available at https://github.com/wywyWang/CoachAI-Projects/tree/main/Movement%20Forecasting.","[""ML: Applications"", ""DMKM: Applications"", ""DMKM: Mining of Spatial"", ""Temporal or Spatio-Temporal Data"", ""DMKM: Other Foundations of Data Mining & Knowledge Management"", ""APP: Other Applications"", ""ML: Graph-based Machine Learning""]","[""Kai-Shiang Chang"", ""Wei-Yao Wang"", ""Wen-Chih Peng""]",https://ojs.aaai.org/index.php/AAAI/article/view/25855/25627,AAAI
Improving Dynamic HDR Imaging with Fusion Transformer,"Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets.","[""CV: Computational Photography"", ""Image & Video Synthesis""]","[""Rufeng Chen"", ""Bolun Zheng"", ""Hua Zhang"", ""Quan Chen"", ""Chenggang Yan"", ""Gregory Slabaugh"", ""Shanxin Yuan""]",https://ojs.aaai.org/index.php/AAAI/article/view/25107/24879,AAAI
Entropy Regularization for Population Estimation,"Entropy regularization is known to improve exploration in sequential decision-making problems. We show that this same mechanism can also lead to nearly unbiased and lower-variance estimates of the mean reward in the optimize-and-estimate structured bandit setting. Mean reward estimation (i.e., population estimation) tasks have recently been shown to be essential for public policy settings where legal constraints often require precise estimates of population metrics. We show that leveraging entropy and KL divergence can yield a better trade-off between reward and estimator variance than existing baselines, all while remaining nearly unbiased. These properties of entropy regularization illustrate an exciting potential for bringing together the optimal exploration and estimation literature.","[""RU: Sequential Decision Making"", ""ML: Active Learning"", ""ML: Online Learning & Bandits""]","[""Ben Chugg"", ""Peter Henderson"", ""Jacob Goldin"", ""Daniel E. Ho""]",https://ojs.aaai.org/index.php/AAAI/article/view/26438/26210,AAAI
Towards Reliable Item Sampling for Recommendation Evaluation,"Since Rendle and Krichene argued that commonly used sampling-based evaluation metrics are ``inconsistent'' with respect to the global metrics (even in expectation), there have been a few studies on the sampling-based recommender system evaluation. Existing methods try either mapping the sampling-based metrics to their global counterparts or more generally, learning the empirical rank distribution to estimate the top-K metrics.
However, despite existing efforts, there is still a lack of rigorous theoretical understanding of the proposed metric estimators, and the basic item sampling also suffers from the ``blind spot'' issue, i.e., estimation accuracy to recover the top-K metrics when K is small can still be rather substantial.
In this paper, we provide an in-depth investigation into these problems and make two innovative contributions. First, we propose a new item-sampling estimator that explicitly optimizes the error with respect to the ground truth, and theoretically highlights its subtle difference against prior work. Second, we propose a new adaptive sampling method that aims to deal with the ``blind spot'' problem and also demonstrate the
expectation-maximization (EM) algorithm can be generalized for such a setting.
Our experimental results confirm our statistical analysis and the superiority of the proposed works.
This study helps lay the theoretical foundation for adopting item sampling metrics for recommendation evaluation and provides strong evidence for making item sampling a powerful and reliable tool for recommendation evaluation.","[""DMKM: Recommender Systems"", ""ML: Evaluation and Analysis (Machine Learning)""]","[""Dong Li"", ""Ruoming Jin"", ""Zhenming Liu"", ""Bin Ren"", ""Jing Gao"", ""Zhi Liu""]",https://ojs.aaai.org/index.php/AAAI/article/view/25561/25333,AAAI
A Tool for Generating Controllable Variations of Musical Themes Using Variational Autoencoders with Latent Space Regularisation,"A common musical composition practice is to develop musical pieces using variations of musical themes. In this study, we present an interactive tool which can generate variations of musical themes in real-time using a variational autoencoder model. Our tool is controllable using semantically meaningful musical attributes via latent space regularisation technique to increase the explainability of the model. The tool is integrated into an industry standard digital audio workstation - Ableton Live - using the Max4Live device framework and can run locally on an average personal CPU rather than requiring a costly GPU cluster. In this way we demonstrate how cutting-edge AI research can be integrated into the exiting workflows of professional and practising musicians for use in the real-world beyond the research lab.","[""Controllable Music Generation"", ""Variational Autoencoder"", ""Latent Space Regularisation"", ""Human-machine Co-creation""]","[""Berker Banar"", ""Nick Bryan-Kinns"", ""Simon Colton""]",https://ojs.aaai.org/index.php/AAAI/article/view/27059/26831,AAAI
Invertible Conditional GAN Revisited: Photo-to-Manga Face Translation with Modern Architectures (Student Abstract),"Recent style translation methods have extended their transferability from texture to geometry. However, performing translation while preserving image content when there is a significant style difference is still an open problem. To overcome this problem, we propose Invertible Conditional Fast GAN (IcFGAN) based on GAN inversion and cFGAN. It allows for unpaired photo-to-manga face translation. Experimental results show that our method could translate styles under significant style gaps, while the state-of-the-art methods could hardly preserve image content.","[""GAN"", ""Manga"", ""GAN Inversion"", ""Image-to-Image Translation""]","[""Taro Hatakeyama"", ""Ryusuke Saito"", ""Komei Hiruta"", ""Atsushi Hashimoto"", ""Satoshi Kurihara""]",https://ojs.aaai.org/index.php/AAAI/article/view/26972/26744,AAAI
Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with Non-stationary Objectives and Constraints,"We consider primal-dual-based reinforcement learning (RL) in episodic constrained Markov decision processes (CMDPs) with non-stationary objectives and constraints, which plays a central role in ensuring the safety of RL in time-varying environments. In this problem, the reward/utility functions and the state transition functions are both allowed to vary arbitrarily over time as long as their cumulative variations do not exceed certain known variation budgets. Designing safe RL algorithms in time-varying environments is particularly challenging because of the need to integrate the constraint violation reduction, safe exploration, and adaptation to the non-stationarity. To this end, we identify two alternative conditions on the time-varying constraints under which we can guarantee the safety in the long run. We also propose the Periodically Restarted Optimistic Primal-Dual Proximal Policy Optimization (PROPD-PPO) algorithm that can coordinate with both two conditions. Furthermore, a dynamic regret bound and a constraint violation bound are established for the proposed algorithm in both the linear kernel CMDP function approximation setting and the tabular CMDP setting under two alternative conditions. This paper provides the first provably efficient algorithm for non-stationary CMDPs with safe exploration.","[""ML: Reinforcement Learning Theory"", ""ML: Reinforcement Learning Algorithms""]","[""Yuhao Ding"", ""Javad Lavaei""]",https://ojs.aaai.org/index.php/AAAI/article/view/25900/25672,AAAI
Relational Program Synthesis with Numerical Reasoning,"Learning programs with numerical values is fundamental to many AI applications, including bio-informatics and drug design. However, current program synthesis approaches struggle to learn programs with numerical values.
An especially difficult problem is learning continuous values from multiple examples, such as intervals. To overcome this limitation, we introduce an inductive logic programming approach which combines relational learning with numerical reasoning. Our approach, which we call NumSynth, uses satisfiability modulo theories solvers to efficiently learn programs with numerical values. Our approach can identify numerical values in linear arithmetic fragments, such as real difference logic, and from infinite domains, such as real numbers or integers. Our experiments on four diverse domains, including game playing and program synthesis, show that our approach can (i) learn programs with numerical values from linear arithmetical reasoning, and (ii) outperform existing approaches in terms of predictive accuracies and learning times.","[""KRR: Logic Programming"", ""CSO: Constraint Programming"", ""ML: Relational Learning""]","[""C\u00e9line Hocquette"", ""Andrew Cropper""]",https://ojs.aaai.org/index.php/AAAI/article/view/25790/25562,AAAI
Constrained Market Share Maximization by Signal-Guided Optimization,"With the rapid development of the airline
industry, maximizing the market share with a
constrained budget is an urgent econometric problem for an airline. We investigate the problem by adjusting flight frequencies on different flight routes. Owing to the large search space of solutions and the difficulty of predicting the market, this problem is in general daunting to solve. This paper proposes a novel two-stage optimization method to address the challenges. On the higher level, we use a signal to guide the optimization process toward a constrained satisfying solution. On the lower level, we consider the consecutive itineraries in real scenarios and model the unseen correlations between routes in itineraries for market share prediction. In theory, we prove the convergence of our optimization approach. In the experiment, we empirically verify the superiority of both our prediction model and optimization approach over existing works with large-scale real-world data. Our code has been released at: https://github.com/codingAndBS/AirlineMarket.","[""DMKM: Applications"", ""APP: Economic/Financial""]","[""Bo Hui"", ""Yuchen Fang"", ""Tian Xia"", ""Sarp Aykent"", ""Wei-Shinn Ku""]",https://ojs.aaai.org/index.php/AAAI/article/view/25552/25324,AAAI
Stroke Extraction of Chinese Character Based on Deep Structure Deformable Image Registration,"Stroke extraction of Chinese characters plays an important role in the field of character recognition and generation. The most existing character stroke extraction methods focus on image morphological features. These methods usually lead to errors of cross strokes extraction and stroke matching due to rarely using stroke semantics and prior information. In this paper, we propose a deep learning-based character stroke extraction method that takes semantic features and prior information of strokes into consideration. This method consists of three parts: image registration-based stroke registration that establishes the rough registration of the reference strokes and the target as prior information; image semantic segmentation-based stroke segmentation that preliminarily separates target strokes into seven categories; and high-precision extraction of single strokes. In the stroke registration, we propose a structure deformable image registration network to achieve structure-deformable transformation while maintaining the stable morphology of single strokes for character images with complex structures. In order to verify the effectiveness of the method, we construct two datasets respectively for calligraphy characters and regular handwriting characters. The experimental results show that our method strongly outperforms the baselines. Code is available at https://github.com/MengLi-l1/StrokeExtraction.","[""CV: Other Foundations of Computer Vision"", ""CV: Applications"", ""CV: Biometrics"", ""Face"", ""Gesture & Pose"", ""CV: Computational Photography"", ""Image & Video Synthesis"", ""CV: Medical and Biological Imaging"", ""CV: Object Detection & Categorization""]","[""Meng Li"", ""Yahan Yu"", ""Yi Yang"", ""Guanghao Ren"", ""Jian Wang""]",https://ojs.aaai.org/index.php/AAAI/article/view/25220/24992,AAAI
Inverse-Reference Priors for Fisher Regularization of Bayesian Neural Networks,"Recent studies have shown that the generalization ability of deep neural networks (DNNs) is closely related to the Fisher information matrix (FIM) calculated during the early training phase. Several methods have been proposed to regularize the FIM for increased generalization of DNNs. However, they cannot be used directly for Bayesian neural networks (BNNs) because the variable parameters of BNNs make it difficult to calculate the FIM. To address this problem, we achieve regularization of the FIM of BNNs by specifying a new suitable prior distribution called the inverse-reference (IR) prior. To regularize the FIM, the IR prior is derived as the inverse of the reference prior that imposes minimal prior knowledge on the parameters and maximizes the trace of the FIM. We demonstrate that the IR prior can enhance the generalization ability of BNNs for large-scale data over previously used priors while providing adequate uncertainty quantifications using various benchmark image datasets and BNN structures.","[""ML: Bayesian Learning""]","[""Keunseo Kim"", ""Eun-Yeol Ma"", ""Jeongman Choi"", ""Heeyoung Kim""]",https://ojs.aaai.org/index.php/AAAI/article/view/25997/25769,AAAI
Low Resource Quantitative Information Extraction via Structure Searching and Prefix-Based Text Generation,"Quantitative information plays an important part in the financial and data analysis areas. Prior work relied on pattern-matching methods and complex hand-crafted rules to extract quantitative information due to the lack of labeled data. Such methods can be unstable and difficult to scale to the open domain. In this paper, we study quantitative information extraction in the low-resource setting. We propose a search-based approach by searching from the syntactic structures to acquire basic training data. The search process is simple yet effective. Then, a prefix-based text-to-text generation method is employed to extract the quantitative information. The prefix design can fully leverage pre-trained language models for text generation to serve the information extraction purpose. Experimental results show that our approaches achieves high performance with a limited amount of labeled data. The extraction result could further boost the performance of other tasks such as quantitative reasoning.","[""SNLP: Information Extraction"", ""SNLP: Generation""]","[""Tongliang Li"", ""Zixiang Wang"", ""Zhoujun Li""]",https://ojs.aaai.org/index.php/AAAI/article/view/26540/26312,AAAI
Accurate Detection of Weld Seams for Laser Welding in Real-World Manufacturing,"Welding is a fabrication process used to join or fuse two mechanical parts. Modern welding machines have automated lasers that follow a pre-defined weld seam path between the two parts to create a bond. Previous efforts have used simple computer vision edge detectors to automatically detect the weld seam edge on an image at the junction of two metals to be welded. However, these systems lack reliability and accuracy resulting in manual human verification of the detected edges. This paper presents a neural network architecture that automatically detects the weld seam edge between two metals with high accuracy. We augment this system with a pre-classifier that filters out anomalous workpieces (e.g., incorrect placement). Finally, we justify our design choices by evaluating against several existing deep network pipelines as well as proof through real-world use. We also describe in detail the process of deploying this system in a real-world shop floor including evaluation and monitoring. We make public a large, well-labeled laser seam dataset to perform deep learning-based edge detection in industrial settings.","[""Machine Learning"", ""Manufacturing"", ""Laser Welding"", ""Computer Vision"", ""Edge Detection"", ""Classification""]","[""Rabia Ali"", ""Muhammad Sarmad"", ""Jawad Tayyub"", ""Alexander Vogel""]",https://ojs.aaai.org/index.php/AAAI/article/view/26834/26606,AAAI
Lightweight Transformer for Multi-Modal Object Detection (Student Abstract),"It has become a common practice for many perceptual systems to integrate information from multiple sensors to improve the accuracy of object detection. For example, autonomous vehicles use visible light, and infrared (IR) information to ensure that the car can cope with complex weather conditions. However, the accuracy of the algorithm is usually a trade-off between the computational complexity and memory consumption. In this study, we evaluate the performance and complexity of different fusion operators in multi-modal object detection tasks. On top of that, a Poolformer-based fusion operator (PoolFuser) is proposed to enhance the accuracy of detecting targets without compromising the efficiency of the detection framework.","[""Transformer"", ""Computer Vision"", ""Multi-modal Fusion"", ""Objection Detection""]","[""Yue Cao"", ""Yanshuo Fan"", ""Junchi Bin"", ""Zheng Liu""]",https://ojs.aaai.org/index.php/AAAI/article/view/26946/26718,AAAI
AI Model Factory: Scaling AI for Industry 4.0 Applications,"This demo paper discusses a scalable platform for emerging Data-Driven AI Applications targeted toward predictive maintenance solutions. We propose a common AI software architecture stack for building diverse AI Applications such as Anomaly Detection, Failure Pattern Analysis, Asset Health Forecasting, etc. for more than a 100K industrial assets of similar class. As a part of the AI system demonstration, we have identified the following three key topics for discussion: Scaling model training across multiple assets, Joint execution of multiple AI applications; and Bridge the gap between current open source software tools and the emerging need for AI Applications. To demonstrate the benefits, AI Model Factory has been tested to build the models for various industrial assets such as Wind turbines, Oil wells, etc. The system is deployed on API Hub for demonstration.","[""AI Model"", ""Automation"", ""Multi-Asset"", ""AI Application"", ""IoT Industry""]","[""Dhaval Patel"", ""Shuxin Lin"", ""Dhruv Shah"", ""Srideepika Jayaraman"", ""Joern Ploennigs"", ""Anuradha Bhamidipati"", ""Jayant Kalagnanam""]",https://ojs.aaai.org/index.php/AAAI/article/view/27081/26853,AAAI
Learning Markov Random Fields for Combinatorial Structures via Sampling through LovÃ¡sz Local Lemma,"Learning to generate complex combinatorial structures satisfying constraints will have transformative impacts in many application domains. However, it is beyond the capabilities of existing approaches due to the highly intractable nature of the embedded probabilistic inference. Prior works spend most of the training time learning to separate valid from invalid structures but do not learn the inductive biases of valid structures. We develop NEural Lovasz Sampler (NELSON), which embeds the sampler through Lovasz Local Lemma (LLL) as a fully differentiable neural network layer. Our NELSON-CD embeds this sampler into the contrastive divergence learning process of Markov random fields. NELSON allows us to obtain valid samples from the current model distribution. Contrastive divergence is then applied to separate these samples from those in the training set. NELSON is implemented as a fully differentiable neural net, taking advantage of the parallelism of GPUs. Experimental results on several real-world domains reveal that NELSON learns to generate 100% valid structures, while baselines either time out or cannot ensure validity. NELSON also outperforms other approaches in running time, log-likelihood, and MAP scores.","[""CSO: Constraint Satisfaction""]","[""Nan Jiang"", ""Yi Gu"", ""Yexiang Xue""]",https://ojs.aaai.org/index.php/AAAI/article/view/25516/25288,AAAI
Inconsistent Cores for ASP: The Perks and Perils of Non-monotonicity,"Answer Set Programming (ASP) is a prominent modeling and solving framework. An inconsistent core (IC) of an ASP program is an inconsistent subset of rules. In the case of inconsistent programs, a smallest or subset-minimal IC contains crucial rules for the inconsistency. In this work, we study fnding minimal ICs of ASP programs and key fragments from a complexity-theoretic perspective. Interestingly, due to ASPâ€™s non-monotonic behavior, also consistent programs admit ICs. It turns out that there is an entire landscape of problems involving ICs with a diverse range of complexities up to the fourth level of the Polynomial Hierarchy. Deciding the existence of an IC is, already for tight programs, on the second level of the Polynomial Hierarchy. Furthermore, we give encodings for IC-related problems on the fragment of tight programs and illustrate feasibility on small instance sets.","[""KRR: Computational Complexity of Reasoning"", ""CSO: Constraint Optimization"", ""KRR: Logic Programming"", ""KRR: Nonmonotonic Reasoning"", ""KRR: Other Foundations of Knowledge Representation & Reasoning""]","[""Johannes K. Fichte"", ""Markus Hecher"", ""Stefan Szeider""]",https://ojs.aaai.org/index.php/AAAI/article/view/25783/25555,AAAI
Leveraging Sub-class Discimination for Compositional Zero-Shot Learning,"Compositional Zero-Shot Learning (CZSL) aims at identifying unseen compositions composed of previously seen attributes and objects during the test phase. In real images, the visual appearances of attributes and objects (primitive concepts) generally interact with each other. Namely, the visual appearances of an attribute may change when composed with different objects, and vice versa. But previous works overlook this important property. In this paper, we introduce a simple yet effective approach with leveraging sub-class discrimination. Specifically, we define the primitive concepts in different compositions as sub-classes, and then maintain the sub-class discrimination to address the above challenge. More specifically, inspired by the observation that the composed recognition models could account for the differences across sub-classes, we first propose to impose the embedding alignment between the composed and disentangled recognition to incorporate sub-class discrimination at the feature level. Then we develop the prototype modulator networks to adjust the class prototypes w.r.t. the composition information, which can enhance sub-class discrimination at the classifier level. We conduct extensive experiments on the challenging benchmark datasets, and the considerable performance improvement over state-of-the-art approaches is achieved, which indicates the effectiveness of our method. Our code is available at https://github.com/hxm97/SCD-CZSL.","[""CV: Object Detection & Categorization"", ""CV: Applications"", ""ML: Transfer"", ""Domain Adaptation"", ""Multi-Task Learning""]","[""Xiaoming Hu"", ""Zilei Wang""]",https://ojs.aaai.org/index.php/AAAI/article/view/25168/24940,AAAI
Evaluating Robustness of Vision Transformers on Imbalanced Datasets (Student Abstract),"Data in the real world is commonly imbalanced across classes. Training neural networks on imbalanced datasets often leads to poor performance on rare classes. Existing work in this area has primarily focused on Convolution Neural Networks (CNN), which are increasingly being replaced by Self-Attention-based Vision Transformers (ViT). Fundamentally, ViTs differ from CNNs in that they offer the flexibility in learning the appropriate inductive bias conducive to improving performance. This work is among the first to evaluate the performance of ViTs under class imbalance. We find that accuracy degradation in the presence of class imbalance is much more prominent in ViTs compared to CNNs. This degradation can be partially mitigated through loss reweighting - a popular strategy that increases the loss contributed by rare classes. We investigate the impact of loss reweighting on different components of a ViT, namely, the patch embedding, self-attention backbone, and linear classifier. Our ongoing investigations reveal that loss reweighting impacts mostly the linear classifier and self-attention backbone while having a small and negligible effect on the embedding layer.","[""Long-tailed Class Distribution/imbalanced Class Dataset"", ""Vision Transformer"", ""Loss-reweighting""]","[""Kevin Li"", ""Rahul Duggal"", ""Duen Horng Chau""]",https://ojs.aaai.org/index.php/AAAI/article/view/26986/26758,AAAI
Causal Inference with Conditional Instruments Using Deep Generative Models,"The instrumental variable (IV) approach is a widely used way to estimate the causal effects of a treatment on an outcome of interest from observational data with latent confounders. A standard IV is expected to be related to the treatment variable and independent of all other variables in the system. However, it is challenging to search for a standard IV from data directly due to the strict conditions. The conditional IV (CIV) method has been proposed to allow a variable to be an instrument conditioning on a set of variables, allowing a wider choice of possible IVs and enabling broader practical applications of the IV approach. Nevertheless, there is not a data-driven method to discover a CIV and its conditioning set directly from data. To fill this gap, in this paper, we propose to learn the representations of the information of a CIV and its conditioning set from data with latent confounders for average causal effect estimation. By taking advantage of deep generative models, we develop a novel data-driven approach for simultaneously learning the representation of a CIV from measured variables and generating the representation of its conditioning set given measured variables. Extensive experiments on synthetic and real-world datasets show that our method outperforms the existing IV methods.","[""ML: Deep Generative Models & Autoencoders"", ""ML: Causal Learning"", ""RU: Causality""]","[""Debo Cheng"", ""Ziqi Xu"", ""Jiuyong Li"", ""Lin Liu"", ""Jixue Liu"", ""Thuc Duy Le""]",https://ojs.aaai.org/index.php/AAAI/article/view/25869/25641,AAAI
Rehabilitating Homeless: Dataset and Key Insights,"This paper presents a large anonymized dataset of homelessness alongside insights into the data-driven rehabilitation of homeless people. The dataset was gathered by a large non-profit organization working on rehabilitating the homeless for twenty years. This is the first dataset that we know of that contains rich information on thousands of homeless individuals seeking rehabilitation. We show how data analysis can help to make the rehabilitation of homeless people more effective and successful. Thus, we hope this paper alerts the data science community to the problem of homelessness.","[""General""]","[""Anna Bykova"", ""Nikolay Filippov"", ""Ivan P. Yamshchikov""]",https://ojs.aaai.org/index.php/AAAI/article/view/26654/26426,AAAI
Overcoming Forgetting in Fine-Grained Urban Flow Inference via Adaptive Knowledge Replay,"Fine-grained urban flow inference (FUFI) problem aims at inferring the high-resolution flow maps from the coarse-grained ones, which plays an important role in sustainable and economic urban computing and traffic management. Previous models addressed the FUFI problem from spatial constraint, external factors, and memory cost. However, utilizing the new urban flow maps to calibrate the learned model is very challenging due to the ""catastrophic forgetting"" problem and is still under-explored. In this paper, we make the first step in FUFI and present CUFAR -- Continual Urban Flow inference with Adaptive knowledge Replay -- a novel framework for inferring the fine-grained citywide traffic flows. Specifically, (1) we design a spatial-temporal inference network that can extract better flow map features from both local and global levels; (2) then we present an adaptive knowledge replay (AKR) training algorithm to selectively replay the learned knowledge to facilitate the learning process of the model on new knowledge without forgetting. In addition, we also propose a knowledge discriminator to avoid ""negative replaying"" issue introduced by noisy urban flow maps. Extensive experiments on four large-scale real-world FUFI datasets demonstrate that our proposed model consistently outperforms strong baselines and effectively mitigates the forgetting problem. Source code is available at: https://github.com/PattonYu/CUFAR.","[""APP: Internet of Things"", ""Sensor Networks & Smart Cities"", ""DMKM: Mining of Spatial"", ""Temporal or Spatio-Temporal Data"", ""APP: Transportation""]","[""Haoyang Yu"", ""Xovee Xu"", ""Ting Zhong"", ""Fan Zhou""]",https://ojs.aaai.org/index.php/AAAI/article/view/25671/25443,AAAI
Diffuser: Efficient Transformers with Multi-Hop Attention Diffusion for Long Sequences,"Efficient Transformers have been developed for long sequence modeling, due to their subquadratic memory and time complexity. Sparse Transformer is a popular approach to improving the efficiency of Transformers by restricting self-attention to locations specified by the predefined sparse patterns. However, leveraging sparsity may sacrifice expressiveness compared to full-attention, when important token correlations are multiple hops away. To combine advantages of both the efficiency of sparse transformer and the expressiveness of full-attention Transformer, we propose Diffuser, a new state-of-the-art efficient Transformer. Diffuser incorporates all token interactions within one attention layer while maintaining low computation and memory costs. The key idea is to expand the receptive field of sparse attention using Attention Diffusion, which computes multi-hop token correlations based on all paths between corresponding disconnected tokens, besides attention among neighboring tokens. Theoretically, we show the expressiveness of Diffuser as a universal sequence approximator for sequence-to-sequence modeling, and investigate its ability to approximate full-attention by analyzing the graph expander property from the spectral perspective. Experimentally, we investigate the effectiveness of Diffuser with extensive evaluations, including language modeling, image modeling, and Long Range Arena (LRA).  Evaluation results show that Diffuser achieves improvements by an average of 0.94% on text classification tasks and 2.30% on LRA, with 1.67x memory savings compared to state-of-the-art benchmarks, which demonstrates superior performance of Diffuser in both expressiveness and efficiency aspects.","[""SNLP: Language Models"", ""ML: Classification and Regression"", ""ML: Deep Neural Network Algorithms"", ""ML: Graph-based Machine Learning"", ""SNLP: Question Answering"", ""SNLP: Text Classification""]","[""Aosong Feng"", ""Irene Li"", ""Yuang Jiang"", ""Rex Ying""]",https://ojs.aaai.org/index.php/AAAI/article/view/26502/26274,AAAI
Multi-View Domain Adaptive Object Detection on Camera Networks,"In this paper, we study a new domain adaptation setting on camera networks, namely Multi-View Domain Adaptive Object Detection (MVDA-OD), in which labeled source data is unavailable in the target adaptation process and target data is captured from multiple overlapping cameras. In such a challenging context, existing methods including adversarial training and self-training fall short due to multi-domain data shift and the lack of source data. To tackle this problem, we propose a novel training framework consisting of two stages. First, we pre-train the backbone using self-supervised learning, in which a multi-view association is developed to construct an effective pretext task. Second, we fine-tune the detection head using robust self-training, where a tracking-based single-view augmentation is introduced to achieve weak-hard consistency learning. By doing so, an object detection model can take advantage of informative samples generated by multi-view association and single-view augmentation to learn discriminative backbones as well as robust detection classifiers. Experiments on two real-world multi-camera datasets demonstrate significant advantages of our approach over the state-of-the-art domain adaptive object detection methods.","[""ML: Transfer"", ""Domain Adaptation"", ""Multi-Task Learning"", ""CV: Applications"", ""CV: Object Detection & Categorization"", ""ML: Unsupervised & Self-Supervised Learning""]","[""Yan Lu"", ""Zhun Zhong"", ""Yuanchao Shu""]",https://ojs.aaai.org/index.php/AAAI/article/view/26077/25849,AAAI
LaCAM: Search-Based Algorithm for Quick Multi-Agent Pathfinding,"We propose a novel complete algorithm for multi-agent pathfinding (MAPF) called lazy constraints addition search for MAPF (LaCAM). MAPF is a problem of finding collision-free paths for multiple agents on graphs and is the foundation of multi-robot coordination. LaCAM uses a two-level search to find solutions quickly, even with hundreds of agents or more. At the low-level, it searches constraints about agents' locations. At the high-level, it searches a sequence of all agents' locations, following the constraints specified by the low-level. Our exhaustive experiments reveal that LaCAM is comparable to or outperforms state-of-the-art sub-optimal MAPF algorithms in a variety of scenarios, regarding success rate, planning time, and solution quality of sum-of-costs.","[""MAS: Multiagent Planning"", ""ROB: Motion and Path Planning"", ""ROB: Multi-Robot Systems"", ""PRS: Deterministic Planning"", ""SO: Heuristic Search""]","[""Keisuke Okumura""]",https://ojs.aaai.org/index.php/AAAI/article/view/26377/26149,AAAI
From Understanding the Population Dynamics of the NSGA-II to the First Proven Lower Bounds,"Due to the more complicated population dynamics of the NSGA-II, none of the existing runtime guarantees for this algorithm is accompanied by a non-trivial lower bound. Via a first mathematical understanding of the population dynamics of the NSGA-II, that is, by estimating the expected number of individuals having a certain objective value, we prove that the NSGA-II with suitable population size needs Omega(Nn log n) function evaluations to find the Pareto front of the OneMinMax problem and Omega(Nn^k)  evaluations on the OneJumpZeroJump problem with jump size k. These bounds are asymptotically tight (that is, they match previously shown upper bounds) and show that the NSGA-II here does not even in terms of the parallel runtime (number of iterations) profit from larger population sizes. For the OneJumpZeroJump problem and when the same sorting is used for the computation of the crowding distance contributions of the two objectives, we even obtain a runtime estimate that is tight including the leading constant.","[""SO: Evolutionary Computation"", ""SO: Heuristic Search""]","[""Benjamin Doerr"", ""Zhongdi Qu""]",https://ojs.aaai.org/index.php/AAAI/article/view/26462/26234,AAAI
An Improved Algorithm for Online Min-Sum Set Cover,"We study a fundamental model of online preference aggregation, where an algorithm maintains an ordered list of n elements. An input is a stream of preferred sets R_1, R_2, ..., R_t, ... Upon seeing R_t and without knowledge of any future sets, an algorithm has to rerank elements (change the list ordering), so that at least one element of R_t is found near the list front. The incurred cost is a sum of the list update costs (the number of swaps of neighboring list elements) and access cost (the position of the first element of R_t on the list). This scenario occurs naturally in applications such as ordering items in an online shop using aggregated preferences of shop customers. The theoretical underpinning of this problem is known as Min-Sum Set Cover.

Unlike previous work that mostly studied the performance of an online algorithm ALG in comparison to the static optimal solution (a single optimal list ordering), in this paper, we study an arguably harder variant where the benchmark is the provably stronger optimal dynamic solution OPT (that may also modify the list ordering). In terms of an online shop, this means that the aggregated preferences of its user base evolve with time. We construct a computationally efficient randomized algorithm whose competitive ratio (ALG-to-OPT cost ratio) is O(r^2) and prove the existence of a deterministic O(r^4)-competitive algorithm. Here, r is the maximum cardinality of sets R_t. This is the first algorithm whose ratio does not depend on n: the previously best algorithm for this problem was O(r^(3/2) * n^(1/2))-competitive and Î©(r) is a lower bound on the performance of any deterministic online algorithm.","[""ML: Learning Preferences or Rankings"", ""ML: Online Learning & Bandits"", ""RU: Other Foundations of Reasoning Under Uncertainty""]","[""Marcin Bienkowski"", ""Marcin Mucha""]",https://ojs.aaai.org/index.php/AAAI/article/view/25835/25607,AAAI
Model Selection of Graph Signage Models Using Maximum Likelihood (Student Abstract),"Complex systems across various domains can be naturally modeled as signed networks with positive and negative edges. In this work, we design a new class of signage models and show how to select the model parameters that best fit real-world datasets using maximum likelihood.","[""Signed Networks"", ""Gene Regulatory Networks"", ""Maximum-likelihood"", ""Markov Chains"", ""Model Fitting""]","[""Angelina Brilliantova"", ""Ivona Bez\u00e1kov\u00e1""]",https://ojs.aaai.org/index.php/AAAI/article/view/26944/26716,AAAI
Latent Space Evolution under Incremental Learning with Concept Drift (Student Abstract),"This work investigates the evolution of latent space when deep learning models are trained incrementally in non-stationary environments that stem from concept drift. We propose a methodology for visualizing the incurred change in latent representations. We further show that classes not targeted by concept drift can be negatively affected, suggesting that the observation of all classes during learning may regularize the latent space.","[""Computer Vision"", ""Incremental Learning"", ""Concept Drift"", ""Catastrophic Interference""]","[""Charles Bourbeau"", ""Audrey Durand""]",https://ojs.aaai.org/index.php/AAAI/article/view/26943/26715,AAAI
Daycare Matching in Japan: Transfers and Siblings,"In this paper, we study a daycare matching problem in Japan and report the design and implementation of a new centralized algorithm, which is going to be deployed in one municipality in the Tokyo metropolis. There are two features that make this market different from the classical hospital-doctor matching problem: i) some children are initially enrolled and prefer to be transferred to other daycare centers; ii) one family may be associated with two or more children and is allowed to submit preferences over combinations of daycare centers. We revisit some well-studied properties including individual rationality, non-wastefulness, as well as stability, and generalize them to this new setting. We design an algorithm based on integer programming (IP) that captures these properties and conduct experiments on five real-life data sets provided by three municipalities. Experimental results show that i) our algorithm performs at least as well as currently used methods in terms of numbers of matched children and blocking coalition; ii) we can find a stable outcome for all instances, although the existence of such an outcome is not guaranteed in theory.","[""General""]","[""Zhaohong Sun"", ""Yoshihiro Takenami"", ""Daisuke Moriwaki"", ""Yoji Tomita"", ""Makoto Yokoo""]",https://ojs.aaai.org/index.php/AAAI/article/view/26694/26466,AAAI
On the Vulnerability of Backdoor Defenses for Federated Learning,"Federated learning (FL) is a popular distributed machine learning paradigm which enables jointly training a global model without sharing clients' data. However, its repetitive server-client communication gives room for possible backdoor attacks which aims to mislead the global model into a targeted misprediction when a specific trigger pattern is presented. In response to such backdoor threats on federated learning, various defense measures have been proposed. In this paper, we study whether the current defense mechanisms truly neutralize the backdoor threats from federated learning in a practical setting by proposing a new federated backdoor attack framework for possible countermeasures. Different from traditional training (on triggered data) and rescaling (the malicious client model) based backdoor injection, the proposed backdoor attack framework (1) directly modifies (a small proportion of) local model weights to inject the backdoor trigger via sign flips; (2) jointly optimize the trigger pattern with the client model,  thus is more persistent and stealthy for circumventing existing defenses. In a case study, we examine the strength and weaknesses of several recent federated backdoor defenses from three major categories and provide suggestions to the practitioners when training federated models in practice.","[""PEAI: Safety"", ""Robustness & Trustworthiness"", ""ML: Adversarial Learning & Robustness""]","[""Pei Fang"", ""Jinghui Chen""]",https://ojs.aaai.org/index.php/AAAI/article/view/26393/26165,AAAI
A Provable Framework of Learning Graph Embeddings via Summarization,"Given a large graph, can we learn its node embeddings from a smaller summary graph? What is the relationship between embeddings learned from original graphs and their summary graphs? Graph representation learning plays an important role in many graph mining applications, but learning em-beddings of large-scale graphs remains a challenge. Recent works try to alleviate it via graph summarization, which typ-ically includes the three steps: reducing the graph size by combining nodes and edges into supernodes and superedges,learning the supernode embedding on the summary graph and then restoring the embeddings of the original nodes. How-ever, the justification behind those steps is still unknown.
In this work, we propose GELSUMM, a well-formulated graph embedding learning framework based on graph sum-marization, in which we show the theoretical ground of learn-ing from summary graphs and the restoration with the three well-known graph embedding approaches in a closed form.Through extensive experiments on real-world datasets, we demonstrate that our methods can learn graph embeddings with matching or better performance on downstream tasks.This work provides theoretical analysis for learning node em-beddings via summarization and helps explain and under-stand the mechanism of the existing works.","[""DMKM: Graph Mining"", ""Social Network Analysis & Community Mining"", ""DMKM: Data Visualization & Summarization"", ""ML: Graph-based Machine Learning"", ""ML: Representation Learning""]","[""Houquan Zhou"", ""Shenghua Liu"", ""Danai Koutra"", ""Huawei Shen"", ""Xueqi Cheng""]",https://ojs.aaai.org/index.php/AAAI/article/view/25621/25393,AAAI
Simulating Network Paths with Recurrent Buffering Units,"Simulating physical network paths (e.g., Internet) is a cornerstone research problem in the emerging sub-field of AI-for-networking. We seek a model that generates end-to-end packet delay values in response to the time-varying load offered by a sender, which is typically a function of the previously output delays. The problem setting is unique, and renders the state-of-the-art text and time-series generative models inapplicable or ineffective. We formulate an ML problem at the intersection of dynamical systems, sequential decision making, and time-series modeling. We propose a novel grey-box approach to network simulation that embeds the semantics of physical network path in a new RNN-style model called Recurrent Buffering Unit, providing the interpretability of standard network simulator tools, the power of neural models, the efficiency of SGD-based techniques for learning, and yielding promising results on synthetic and real-world network traces.","[""ML: Applications"", ""APP: Communication"", ""APP: Web"", ""ML: Deep Generative Models & Autoencoders"", ""ML: Time-Series/Data Streams""]","[""Divyam Anshumaan"", ""Sriram Balasubramanian"", ""Shubham Tiwari"", ""Nagarajan Natarajan"", ""Sundararajan Sellamanickam"", ""Venkat N. Padmanabhan""]",https://ojs.aaai.org/index.php/AAAI/article/view/25820/25592,AAAI
Multi-Unit Auctions for Allocating Chance-Constrained Resources,"Sharing scarce resources is a key challenge in multi-agent interaction, especially when individual agents are uncertain about their future consumption.  We present a new auction mechanism for preallocating multi-unit resources among agents, while limiting the chance of resource violations. By planning for a chance constraint, we strike a balance between worst-case approaches, which under-utilise resources, and expected-case approaches, which lack formal guarantees. We also present an algorithm that allows agents to generate bids via multi-objective reasoning, which are then submitted to the auction. We then discuss how the auction can be extended to non-cooperative scenarios. Finally, we demonstrate empirically that our auction outperforms state-of-the-art  techniques for chance-constrained multi-agent resource allocation in complex settings with up to hundreds of agents.","[""MAS: Multiagent Planning"", ""MAS: Multiagent Systems Under Uncertainty"", ""GTEP: Auctions and Market-Based Systems"", ""PRS: Planning Under Uncertainty"", ""PRS: Planning With Markov Models (MDPs"", ""POMDPs)""]","[""Anna Gautier"", ""Bruno Lacerda"", ""Nick Hawes"", ""Michael Wooldridge""]",https://ojs.aaai.org/index.php/AAAI/article/view/26366/26138,AAAI
Weakly Supervised 3D Segmentation via Receptive-Driven Pseudo Label Consistency and Structural Consistency,"As manual point-wise label is time and labor-intensive for fully supervised large-scale point cloud  semantic segmentation, weakly supervised method is increasingly active. However, existing methods fail to generate high-quality pseudo labels effectively, leading to unsatisfactory results. In this paper, we propose a weakly supervised point cloud semantic segmentation framework via receptive-driven pseudo label consistency and structural consistency to mine potential knowledge. Specifically, we propose three consistency contrains: pseudo label consistency among different scales,  semantic structure consistency between intra-class features and class-level relation structure consistency between pair-wise categories.  Three consistency constraints are jointly used to effectively prepares and utilizes pseudo labels simultaneously for stable training. Finally, extensive experimental results on three challenging datasets demonstrate that our method significantly outperforms state-of-the-art weakly supervised methods and even achieves comparable performance to the fully supervised methods.","[""CV: 3D Computer Vision"", ""CV: Segmentation""]","[""Yuxiang Lan"", ""Yachao Zhang"", ""Yanyun Qu"", ""Cong Wang"", ""Chengyang Li"", ""Jia Cai"", ""Yuan Xie"", ""Zongze Wu""]",https://ojs.aaai.org/index.php/AAAI/article/view/25205/24977,AAAI
Demystifying Randomly Initialized Networks for Evaluating Generative Models,"Evaluation of generative models is mostly based on the comparison between the estimated distribution and the ground truth distribution in a certain feature space. To embed samples into informative features, previous works often use convolutional neural networks optimized for classification, which is criticized by recent studies. Therefore, various feature spaces have been explored to discover alternatives. Among them, a surprising approach is to use a randomly initialized neural network for feature embedding. However, the fundamental basis to employ the random features has not been sufficiently justified. In this paper, we rigorously investigate the feature space of models with random weights in comparison to that of trained models. Furthermore, we provide an empirical evidence to choose networks for random features to obtain consistent and reliable results. Our results indicate that the features from random networks can evaluate generative models well similarly to those from trained networks, and furthermore, the two types of features can be used together in a complementary way.","[""ML: Deep Generative Models & Autoencoders"", ""ML: Evaluation and Analysis (Machine Learning)""]","[""Junghyuk Lee"", ""Jun-Hyuk Kim"", ""Jong-Seok Lee""]",https://ojs.aaai.org/index.php/AAAI/article/view/26022/25794,AAAI
Fundamentals of Task-Agnostic Data Valuation,"We study valuing the data of a data owner/seller for a data seeker/buyer. Data valuation is often carried out for a specific task assuming a particular utility metric, such as test accuracy on a validation set, that may not exist in practice. In this work, we focus on task-agnostic data valuation without any validation requirements. The data buyer has access to a limited amount of data (which could be publicly available) and seeks more data samples from a data seller. We formulate the problem as estimating the differences in the statistical properties of the data at the seller with respect to the baseline data available at the buyer. We capture these statistical differences through second moment by measuring diversity and relevance of the sellerâ€™s data for the buyer; we estimate these measures through queries to the seller without requesting the raw data. We design the queries with the proposed approach so that the seller is blind to the buyerâ€™s raw data and has no knowledge to fabricate responses to the queries to obtain a desired outcome of the diversity and relevance trade-off. We will show through extensive experiments on real tabular and image datasets that the proposed estimates capture the diversity and relevance of the sellerâ€™s data for the buyer.","[""ML: Distributed Machine Learning & Federated Learning"", ""GTEP: Auctions and Market-Based Systems"", ""GTEP: Applications"", ""ML: Learning on the Edge & Model Compression""]","[""Mohammad Mohammadi Amiri"", ""Frederic Berdoz"", ""Ramesh Raskar""]",https://ojs.aaai.org/index.php/AAAI/article/view/26106/25878,AAAI
